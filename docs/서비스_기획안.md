# 데이터 분석 시간 예측 서비스 기획안

## 1. 서비스 개요

### 1.1 서비스명
- **서비스명**: (사용자와 함께 결정 필요)
- **영문명**: (사용자와 함께 결정 필요)

### 1.2 서비스 목적 및 비전
데이터 분석 프로젝트를 시작하기 전에, 데이터의 규모와 선택한 분석 방법, 사용할 툴, 하드웨어 성능을 기반으로 **실제 벤치마크 데이터를 활용하여** 분석에 소요될 시간을 정확하게 예측하는 서비스입니다.

**비전**: 데이터 분석가와 프로젝트 관리자가 분석 작업의 시간을 정확하게 예측하여 효율적인 프로젝트 계획을 수립할 수 있도록 돕습니다.

**핵심 철학**: 
- 쉽고 빠른 사용성 - 복잡한 설정 없이 바로 예측
- 높은 정확도 - 실제 측정 데이터 기반 예측 (목표: ±30% 이내)

### 1.3 해결하고자 하는 문제
- 데이터 분석 프로젝트의 소요 시간을 사전에 예측하기 어려움
- 프로젝트 계획 수립 시 실제 분석 시간을 고려하지 못해 일정 지연 발생
- 다양한 분석 방법과 툴 중 어떤 조합이 가장 효율적인지 판단하기 어려움
- 분석 작업 시작 전 예상 시간을 알 수 없어 리소스 배분이 어려움

### 1.4 타겟 사용자
- **데이터 분석가/데이터 사이언티스트**: 분석 작업 전 소요 시간을 예측하여 작업 계획 수립
- **비즈니스 분석가**: 분석 프로젝트의 일정과 리소스를 사전에 계획
- **프로젝트 매니저/기획자**: 프로젝트 일정 수립 시 분석 시간을 정확히 반영
- **개발자**: 데이터 처리 및 분석 작업의 소요 시간 예측

---

## 2. 핵심 가치 제안

### 2.1 사용자가 얻을 수 있는 가치
1. **정확한 시간 예측**: 실제 벤치마크 데이터 기반으로 높은 정확도의 시간 예측 (목표: ±30%)
2. **쉽고 빠른 사용**: 몇 번의 클릭만으로 즉시 예측 결과 확인
3. **하드웨어 고려**: 사용자의 시스템 성능을 반영한 맞춤형 예측
4. **신뢰 구간 제공**: 최소-최대 예상 시간 범위로 불확실성 파악
5. **최적화 추천 (선택)**: 더 빠른 분석을 위한 방법 제안 (사용자 선택에 따라)

### 2.2 기존 솔루션과의 차별점
- **실측 데이터 기반**: 단순 추정이 아닌 실제 벤치마크 데이터 활용 (scitime 방식 참고)
- **하드웨어 보정**: 사용자 시스템 성능을 반영한 정확한 예측
- **높은 정확도**: 유사도 기반 보간법으로 정확도 향상 (목표: ±30%)
- **즉시 사용 가능**: 복잡한 설정 없이 바로 예측
- **접근성**: 비전공자도 쉽게 사용 가능한 직관적 인터페이스

---

## 3. MVP 기능 정의

### 3.1 핵심 기능: 분석 시간 예측

#### 3.1.1 입력 정보
- **데이터 정보**
  - 데이터 크기 (행 수, 열 수)
  - 데이터 형식 (CSV, Excel, 데이터베이스 등)
- **분석 방법**
  - 분석 유형 (회귀분석, 분류, 클러스터링, 딥러닝 등)
- **사용 툴**
  - 분석 도구 (Python, R, SQL, Excel 등)
- **하드웨어 정보 (선택사항)**
  - CPU 성능 (저사양/중간/고사양/최고사양)
  - RAM 용량 (8GB/16GB/32GB/64GB)
  - 스토리지 타입 (HDD/SATA SSD/NVMe SSD)
  - *간단한 선택지 제공, 기본값 사용 가능*

#### 3.1.2 출력 정보
- **예상 소요 시간**
  - 전체 분석 시간 (중앙값)
  - 신뢰 구간 (최소-최대 예상 시간)
  - 예측 신뢰도 표시
- **단계별 시간 분해**
  - 데이터 로딩 (20%)
  - 데이터 전처리 (30%)
  - 분석 실행 (50%)
- **예측 근거 정보**
  - 사용된 벤치마크 데이터 개수
  - 유사도 점수
- **최적화 추천사항 (선택적)**
  - 사용자가 원할 경우에만 표시
  - 더 빠른 툴/방법 제안

#### 3.1.3 입력 방식
- **폼 입력**: 구조화된 폼을 통한 정보 입력
- **자연어 입력**: "100만 행의 데이터를 Python Pandas로 회귀분석하고 싶어"와 같은 자연어 입력 지원

---

## 4. 사용자 시나리오

### 4.1 페르소나별 시나리오

#### 시나리오 1: 데이터 분석가 (김분석)
- **상황**: 새로운 데이터셋으로 고객 세그멘테이션 분석을 시작하려고 함
- **목표**: 분석에 소요될 시간을 예측하여 일정 계획 수립
- **행동**: 
  1. 서비스에 접속
  2. 데이터 정보 입력 (50만 행, 20개 컬럼, CSV 파일)
  3. 분석 방법 선택 (K-means 클러스터링)
  4. 사용 툴 선택 (Python, Scikit-learn)
  5. 예상 시간 확인 및 최적화 추천 검토
  6. 결과를 바탕으로 작업 일정 수립

#### 시나리오 2: 프로젝트 매니저 (박기획)
- **상황**: 데이터 분석 프로젝트의 일정을 수립해야 함
- **목표**: 분석 작업의 소요 시간을 파악하여 전체 프로젝트 일정에 반영
- **행동**:
  1. 자연어로 입력: "10만 건의 주문 데이터로 매출 예측 회귀분석"
  2. 예상 시간 확인
  3. 여러 분석 방법의 시간을 비교하여 최적의 방법 선택
  4. 프로젝트 일정표에 분석 시간 반영

#### 시나리오 3: 비즈니스 분석가 (이비즈)
- **상황**: Excel로 간단한 데이터 분석을 계획 중
- **목표**: Excel로 충분한지, 다른 툴이 필요한지 판단
- **행동**:
  1. 데이터 규모 입력 (5만 행)
  2. Excel과 Python의 예상 시간 비교
  3. 추천사항을 바탕으로 툴 선택 결정

### 4.2 사용자 여정 (User Journey)

```
1. 인지 (Awareness)
   → 데이터 분석 프로젝트 계획 필요성 인식

2. 탐색 (Exploration)
   → 서비스 접속 및 기능 확인

3. 입력 (Input)
   → 데이터 정보, 분석 방법, 툴 정보 입력
   → 폼 입력 또는 자연어 입력 선택

4. 예측 확인 (Prediction)
   → 예상 시간 및 최적화 추천 확인

5. 의사결정 (Decision)
   → 예측 결과를 바탕으로 분석 방법/툴 최종 결정
   → 프로젝트 일정 수립

6. 실행 (Action)
   → 실제 분석 작업 진행
```

---

## 5. 기능 상세

### 5.1 분석 시간 예측 기능

#### 입력 항목 상세 정의

**데이터 정보**
- 데이터 크기
  - 행 수 (Number of rows)
  - 열 수 (Number of columns)
  - 파일 크기 (File size in MB/GB)
- 데이터 형식
  - CSV
  - Excel (.xlsx, .xls)
  - 데이터베이스 (MySQL, PostgreSQL, MongoDB 등)
  - JSON
  - 기타
- 데이터 유형
  - 수치형 데이터 비율
  - 범주형 데이터 비율
  - 텍스트 데이터 비율
  - 결측치 비율 (선택사항)

**분석 방법**
- 분석 유형
  - 회귀분석 (선형, 다중, 로지스틱 등)
  - 분류 (의사결정나무, 랜덤포레스트, SVM 등)
  - 클러스터링 (K-means, 계층적 클러스터링 등)
  - 시계열 분석
  - 연관규칙 분석
  - 기타
- 분석 복잡도
  - 단순 (Simple)
  - 중간 (Medium)
  - 복잡 (Complex)

**사용 툴**
- 프로그래밍 언어/도구
  - Python (Pandas, Scikit-learn)
  - R (dplyr, caret)
  - SQL
  - Excel
  - 기타

**하드웨어 정보 (선택사항)**
- CPU 성능
  - 저사양 (i3, 8GB)
  - 중간 (i5, 16GB) - 기본값
  - 고사양 (i7, 32GB)
  - 최고사양 (i9, 64GB+)
- 스토리지 타입
  - HDD
  - SATA SSD - 기본값
  - NVMe SSD
- *하드웨어 정보를 입력하면 더 정확한 예측 가능*
- *입력하지 않으면 중간 사양 기준으로 예측*

#### 출력 항목 상세 정의

**예상 소요 시간**
- 전체 예상 시간
  - 중앙값: 예상되는 시간
  - 신뢰 구간: 최소~최대 범위
  - 예: "약 5.2분 (4.1분 ~ 6.5분)"
- 단계별 시간 분해
  - 데이터 로딩: 1.0분 (20%)
  - 데이터 전처리: 1.6분 (30%)
  - 분석 실행: 2.6분 (50%)
- 예측 신뢰도
  - 사용된 벤치마크: 5개
  - 예측 신뢰도: ±25%

**예측 방법 정보**
- 어떻게 예측했는지 간단한 설명
- 예: "유사한 5개의 실제 측정 데이터를 기반으로 예측"
- 벤치마크 데이터가 충분하면 "높은 신뢰도", 부족하면 "추정값" 표시

**최적화 추천사항 (선택적 표시)**
- 기본적으로 숨김 처리
- 사용자가 "최적화 방법 보기" 클릭 시에만 표시
- 더 빠른 툴 제안
- 데이터 샘플링 제안

### 5.2 입력 방식

#### 폼 입력
- 구조화된 입력 폼 제공
- 단계별 입력 가이드
- 입력값 검증 및 피드백

#### 자연어 입력
- 자연어로 분석 요구사항 입력
- 예시:
  - "100만 행의 고객 데이터로 클러스터링 분석"
  - "Python으로 50만 건의 주문 데이터 회귀분석"
- 입력된 자연어를 자동으로 구조화된 정보로 변환

---

## 6. MVP 범위

### 6.1 MVP에 포함되는 기능
- ✅ 데이터 정보 입력 (행 수, 열 수)
- ✅ 분석 방법 선택
- ✅ 사용 툴 선택
- ✅ 하드웨어 정보 입력 (선택사항, 기본값 제공)
- ✅ 벤치마크 기반 시간 예측
- ✅ 신뢰 구간 표시
- ✅ 단계별 시간 분해
- ✅ 예측 신뢰도 표시
- ✅ 폼 입력 방식
- ⚠️ 최적화 추천 (선택적 표시, 클릭 시에만)

### 6.2 MVP에서 제외되는 기능 (향후 확장)
- ❌ 자연어 입력
- ❌ 분석 기록 저장 및 히스토리 관리
- ❌ 여러 분석 방법/툴 동시 비교
- ❌ 실시간 샘플링 테스트
- ❌ 비구조화 데이터 (이미지, 텍스트 등) 지원
- ❌ 예상 비용 계산 (클라우드 리소스 등)
- ❌ 사용자 계정 및 개인화 기능
- ❌ 예측 결과 리포트 다운로드
- ❌ API 제공
- ❌ 모바일 앱

---

## 7. 성공 지표

### 7.1 사용자 지표
- **사용자 수**: 월간 활성 사용자 수 (MAU)
- **사용 빈도**: 사용자당 평균 사용 횟수
- **재사용률**: 한 번 사용한 사용자의 재방문률

### 7.2 기능 지표
- **예측 정확도**: 실제 분석 시간 대비 예측 시간의 오차율
- **입력 방식 사용률**: 폼 입력 vs 자연어 입력 사용 비율
- **추천 수용률**: 제시된 최적화 추천을 실제로 적용한 비율

### 7.3 비즈니스 지표
- **사용자 만족도**: 사용자 피드백 및 만족도 점수
- **문제 해결률**: 사용자가 원하는 정보를 얻은 비율
- **시간 절감 효과**: 사용자가 실제로 절감한 계획 수립 시간

---

## 8. 향후 확장 계획 (참고)

### 8.1 단기 확장 (Phase 2)
- 분석 기록 저장 및 관리
- 여러 분석 방법/툴 동시 비교 기능
- 예측 결과 리포트 생성 및 다운로드

### 8.2 중기 확장 (Phase 3)
- 비구조화 데이터 지원
- 예상 비용 계산 기능
- 사용자 계정 및 개인화 기능

### 8.3 장기 확장 (Phase 4)
- API 제공
- 모바일 앱 개발
- 협업 기능 (팀 단위 분석 계획 수립)

---

---

## 9. 예측 방법론

### 9.1 벤치마크 기반 예측 시스템

**핵심 원리**: 실제로 측정한 데이터를 기반으로 예측

```
1. 벤치마크 데이터베이스
   - 다양한 조건에서 실제 측정한 시간 저장
   - 예: "100만 행 × 20열 × 회귀분석 × Python = 42초"

2. 유사도 계산
   - 사용자 입력과 가장 유사한 벤치마크 찾기
   - 데이터 크기, 분석 방법, 툴 등을 고려

3. 보간법 예측
   - 유사한 벤치마크 3-5개 사용
   - 가중 평균으로 예측 시간 계산

4. 하드웨어 보정
   - 사용자 CPU, RAM, 스토리지 성능 반영
   - 기준 사양 대비 비율로 조정

5. 신뢰 구간 계산
   - 벤치마크가 많을수록 신뢰도 높음
   - ±20% ~ ±50% 범위 제공
```

### 9.2 예측 정확도 목표

| 벤치마크 데이터 수 | 예측 정확도 목표 |
|-------------------|----------------|
| 10개 이상 | ±50% |
| 50개 이상 | ±30% (목표) |
| 100개 이상 | ±20% |

### 9.3 성능 영향 요소

**데이터 크기**
- 행 수가 10배 증가 → 시간 10배 증가 (선형)
- 단, 100만 행 이상은 비선형 (1.2배 추가 패널티)

**열 수**
- 열 수가 2배 증가 → 시간 약 1.5배 증가
- 메모리 사용량에 직접적 영향

**분석 복잡도**
- 단순 집계: O(n) - 가장 빠름
- 회귀분석: O(n×m²) - m은 열 수
- 클러스터링: O(n×k×i) - k는 클러스터 수, i는 반복 횟수
- 딥러닝: O(n×m×epochs) - 가장 느림

**하드웨어 영향**
- CPU: 2배 빠른 CPU → 약 1.8배 빠름
- RAM: 충분하면 1.0, 부족하면 1.5배 느림
- 스토리지: NVMe SSD가 HDD보다 1.5-2배 빠름

---

## 10. 기술적 참고사항

### 10.1 참고 프로젝트
- **scitime**: Scikit-learn 알고리즘 학습 시간 예측 라이브러리
  - GitHub: github.com/scitime/scitime
  - 메타 학습 모델 사용
  - 실제 측정 기반 예측

### 10.2 벤치마크 데이터 수집
- Python 스크립트로 자동 측정
- 다양한 크기, 방법, 툴 조합 테스트
- JSON 형식으로 저장

### 10.3 예측 알고리즘
1. K-nearest neighbors 방식의 유사도 계산
2. 선형 보간법
3. 하드웨어 성능 비율 적용
4. 신뢰 구간 계산

---

## 부록: 용어 정의

- **데이터 분석**: 데이터를 수집, 정제, 분석하여 인사이트를 도출하는 과정
- **분석 시간**: 데이터 로딩부터 결과 도출까지의 전체 소요 시간
- **벤치마크**: 특정 조건에서 실제로 측정한 성능 데이터
- **신뢰 구간**: 예측값의 불확실성을 나타내는 최소-최대 범위
- **보간법**: 알려진 값 사이의 값을 추정하는 수학적 방법
- **MVP (Minimum Viable Product)**: 최소 기능 제품, 핵심 기능만 포함한 초기 버전
