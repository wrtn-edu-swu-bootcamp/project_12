# 데이터 분석 시간 예측 서비스 기획안

## 1. 서비스 개요

### 서비스명
**Data Analysis Time Predictor**

### 핵심 가치
**"쉽고 빠르게, 분석 시간을 미리 알자!"**

### 서비스 목적
데이터 분석 시작 전에 **30초 입력 → 1초 예측**으로 분석 소요 시간을 즉시 확인

### 해결하는 문제
- "이 데이터 분석하는데 얼마나 걸릴까?"
- "점심 먹고 오면 끝날까?"
- "퇴근 전에 결과가 나올까?"

### 차별점
| 구분 | 기존 방식 | 본 서비스 |
|------|---------|----------|
| 시점 | 분석 실행 후 | 분석 실행 전 |
| 소요시간 | 전체 분석 시간 | 매우 짧은 시간 |
| 정확도 | 100% | 70-80% |
| 비용 | 리소스 소비 | 거의 없음 |

---

## 2. 핵심 기능

### 입력 항목 (30초 이내)
1. **데이터 정보** (필수)
   - 행 수, 열 수
   
2. **분석 방법** (필수)
   - 17개 방법: 단순 집계(3) / 회귀(4) / 분류(4) / 클러스터링(4) / 딥러닝(2)
   
3. **툴 선택** (필수)
   - Python, R, SQL, Excel
   
4. **하드웨어** (필수)
   - 저사양 / 중간 / 고사양 / 최고사양
   - 성능 차이: 최대 5-10배
   - **사양 기준**:
     - 저사양: 2코어, 4GB RAM, HDD
     - 중간: 4코어, 8-16GB RAM, SSD
     - 고사양: 8코어, 32GB RAM, SSD
     - 최고사양: 16코어 이상, 64GB+ RAM, SSD + GPU

5. **데이터 타입** (필수)
   - 수치형 / 범주형 / 텍스트 비율
   - 각 타입의 비율 합계 100%

### 출력 정보 (1초 이내)
1. **예상 소요 시간** ⭐
   - 중앙값 (가장 가능성 높은 시간)
   
2. **신뢰 구간** ⭐
   - 최소~최대 범위 (항상 표시)
   - 예: 30분 ~ 60분 (70% 확률)
   
3. **예측 신뢰도**
   - High (±20%) / Medium (±30%) / Low (±50%)
   
4. **단계별 분해**
   - 로딩(20%) / 전처리(30%) / 분석(50%)
   
5. **최적화 추천** (선택사항)
   - 기본: 숨김 처리
   - 토글로 활성화 가능

---

## 3. 타겟 사용자

### 주요 페르소나

**1. 데이터 분석가 (민수, 28세)**
- 니즈: "점심 먹고 오면 끝날까?"
- 시나리오: 100만 행 랜덤 포레스트 → 예측 45분 → 점심시간 활용 결정

**2. 비즈니스 분석가 (지영, 32세)**
- 니즈: "회의 전에 결과 낼 수 있을까?"
- 시나리오: 50만 행 집계 → 예측 12분 → 안심하고 실행

**3. PM/기획자 (현우, 35세)**
- 니즈: "일정 계획에 반영하려면?"
- 시나리오: 3가지 옵션 비교 (3초) → 샘플링 방식 선택

**4. 학생/연구자 (수진, 24세)**
- 니즈: "집 vs 학교 서버?"
- 시나리오: 두 환경 비교 (2초) → 학교 서버 예약 결정

---

## 4. 예측 방법론

### MVP: 벤치마크 기반
- 실제 측정 데이터에서 유사 케이스 찾기
- 하드웨어 차이 보정
- 신뢰 구간 자동 계산

### Phase 2: 메타 학습 추가
- scitime 방식 참고 (랜덤 포레스트/신경망)
- 정확도 향상: ±30% → ±20%

### 정확도 목표
| Phase | 목표 | 방법 |
|-------|------|------|
| MVP | ±30% | 벤치마크 |
| Phase 2 | ±20% | 벤치마크 + ML |
| Phase 3 | ±15% | 고도화 |

---

## 5. 성능 영향 요소

### 주요 요소
| 요소 | 영향도 | 시간 변화 | 
|------|--------|----------|
| 데이터 크기(행) | ⭐⭐⭐⭐⭐ | 선형 비례 |
| 하드웨어 | ⭐⭐⭐⭐⭐ | 2-10배 |
| 툴/라이브러리 | ⭐⭐⭐⭐ | 1-25배 |
| 데이터 타입 | ⭐⭐⭐ | 1-3배 |
| 데이터 크기(열) | ⭐⭐⭐⭐ | 0.5-2배 |

### 세부 설명

**데이터 크기**
- 행 2배 → 시간 2배 (선형)
- 열 2배 → 시간 1.5-2배

**하드웨어**
- RAM 부족 시 → 10배 이상 느려짐
- CPU 코어 수 → 병렬 처리 가능 알고리즘에 영향
- 저사양→중간: 2-3배, 중간→고사양: 2-3배

**데이터 타입**
- 수치형: 기준 (가장 빠름)
- 범주형: 1.5배 느림
- 텍스트: 2-3배 느림 (메모리 많이 사용)

**툴 선택**
- Pandas: 기준 (1x)
- Polars: 5-25배 빠름
- SQL: 집계 작업에 최적화

---

## 6. MVP 범위

### 포함 (P0 - 필수)
✅ 빠른 예측 (30초 입력, 1초 결과)  
✅ 17개 분석 방법  
✅ 하드웨어 성능 반영  
✅ 신뢰 구간 항상 표시  
✅ 단계별 시간 분해  

### 포함 (P1 - 권장)
⚡ 데이터 타입 입력  
⚡ 예측 신뢰도 표시  
⚡ 성능 영향 요소 설명  

### 선택 (P2)
⚠️ 최적화 추천 (기본 숨김, 토글)  
⚠️ 분석 기록 저장  

### 제외 (Phase 2 이후)
❌ 자연어 입력  
❌ 여러 옵션 동시 비교  
❌ 회원가입  
❌ API 제공  

---

## 7. 성공 지표 (KPI)

### 핵심 지표
1. **사용성**: 방문자의 80% 이상 예측 수행
2. **정확도**: ±30% 이내
3. **만족도**: 5점 만점 4.0 이상
4. **응답 시간**: 1초 이내 결과 제공
5. **재방문율**: 월 2회 이상 50%

---

## 8. 향후 로드맵

### Phase 1: MVP (현재, 1-2주)
- 기본 HTML 웹페이지
- 17개 분석 방법
- 신뢰 구간 표시
- GitHub Pages 배포

### Phase 2: 정확도 개선 (2-3개월)
- 벤치마크 데이터 50개 수집
- 메타 학습 모델 도입
- 정확도 ±30% → ±20%
- 최적화 추천 (피드백 후 결정)

### Phase 3: 고급 기능 (6개월)
- 자연어 입력
- 분석 기록 저장
- 여러 옵션 동시 비교
- 결과 다운로드

### Phase 4: 확장 (1년)
- 회원가입 및 개인화
- API 제공
- 모바일 앱

---

## 9. 리스크 및 대응

### 주요 리스크

**1. 정확도 부족**
- 대응: 신뢰 구간 명시, "대략적 예측" 안내

**2. 다양한 케이스 커버**
- 대응: "기타" 옵션, 가장 가까운 방법 추천

**3. 하드웨어 다양성**
- 대응: 넓은 신뢰 구간, 4단계 분류로 충분

---

## 10. 결론

### MVP 성공 기준
1. ✅ 30초 이내 입력 (쉬움)
2. ✅ 1초 이내 결과 (빠름)
3. ✅ ±30% 정확도 (실용적)
4. ✅ 신뢰 구간 표시 (투명함)
5. ✅ 만족도 4.0+ (유용함)

### 핵심 차별점
- ⚡ **속도**: 즉시 예측
- 🎯 **편의성**: 간단한 입력
- 📊 **투명성**: 신뢰 구간 명시
- 🆓 **접근성**: 무료 웹 서비스
- 💡 **집중성**: 핵심 기능에 집중

### 다음 단계
1. 사용자 테스트 (5-10명)
2. 피드백 반영
3. 공개 배포 (GitHub Pages)
4. 사용자 확대

---

**문서 버전**: 1.2 (간소화)  
**작성일**: 2026년 1월  
**작성자**: Project Team
