# 데이터 분석 시간 예측 서비스 기획안

## 1. 서비스 개요

### 서비스명
**Data Analysis Time Predictor** (데이터 분석 시간 예측 서비스)

### 서비스 목적
데이터 분석 프로젝트를 시작하기 전에, 데이터 규모와 분석 방법, 하드웨어 성능을 기반으로 분석 소요 시간을 빠르고 쉽게 예측하는 서비스

### 기존 솔루션 참고
본 서비스는 **scitime** (Scikit-learn 알고리즘의 학습 시간 예측 Python 라이브러리)과 유사한 접근 방식을 채택하되, 다음과 같은 차별점을 갖습니다:

**scitime의 접근:**
- 메타 알고리즘(랜덤 포레스트 또는 신경망)을 사용하여 학습 시간 예측
- 데이터 크기, 알고리즘 유형, 하드웨어 성능을 고려
- 신뢰 구간 제공

**본 서비스의 차별점:**
- 📱 **웹 기반**: 별도 설치 없이 브라우저에서 즉시 사용
- 🎯 **더 넓은 범위**: Scikit-learn 외 다양한 분석 도구 (R, SQL, Excel 등) 지원
- ⚡ **더 빠른 응답**: 복잡한 모델 학습 없이 벤치마크 기반 예측
- 🔍 **단계별 분해**: 로딩, 전처리, 분석 시간 구분 표시

### 해결하고자 하는 문제

**사용자의 고민:**
- "이 데이터를 분석하는데 얼마나 걸릴까?"
- "회의가 한 시간 후인데, 지금 돌리면 끝날까?"
- "밤새 돌리면 아침에 결과가 나올까?"
- "더 빠른 방법은 없을까?"

**기존 방식의 문제점:**
- 분석을 직접 돌려봐야 시간을 알 수 있음
- 경험이 없으면 예측이 어려움
- 대용량 데이터는 테스트조차 시간 낭비
- 하드웨어 차이를 고려하기 어려움

### 핵심 가치
**"쉽고 빠르게, 분석 시간을 미리 알자!"**

본 서비스의 핵심은 **속도와 편의성**입니다. 복잡한 설정이나 설치 없이, 몇 가지 간단한 입력만으로 30초 이내에 분석 시간을 예측할 수 있습니다. 최적화 추천과 같은 고급 기능은 선택사항으로 제공되며, 사용자는 필요에 따라 활용할 수 있습니다.

---

## 2. 핵심 가치 제안

### 사용자가 얻을 수 있는 가치

#### 1. 시간 절약
- 테스트 없이 즉시 예측 (30초 내)
- 불필요한 대기 시간 제거
- 효율적인 일정 관리

#### 2. 쉬운 사용성
- 단순한 입력만으로 예측 가능
- 복잡한 설정 불필요
- 누구나 바로 사용 가능

#### 3. 정확한 예측
- 실제 벤치마크 데이터 기반
- 하드웨어 성능 고려
- 신뢰 구간 제공

#### 4. 현명한 의사결정
- 분석 방법 선택 지원
- 하드웨어 업그레이드 판단 근거
- 마감 시간 관리

#### 5. 선택적 최적화 제안 (Optional)
- 더 빠른 대안 방법 추천
- 하드웨어 업그레이드 효과 예측
- 데이터 샘플링 제안
- **참고**: 기본 시간 예측과 별도로 선택적으로 활성화 가능

### 기존 솔루션과의 차별점

| 구분 | 기존 방식 | 본 서비스 |
|------|---------|----------|
| **사용 시점** | 분석 실행 후 | 분석 실행 전 |
| **소요 시간** | 실제 분석 시간 전체 | 30초 이내 |
| **복잡도** | 높음 (실제 실행) | 낮음 (간단 입력) |
| **정확도** | 100% (실제 측정) | 70-80% (예측) |
| **비용** | 컴퓨팅 리소스 소비 | 거의 없음 |
| **하드웨어 고려** | 어려움 | 자동 반영 |

**차별화 포인트:**
- ⚡ **빠른 응답**: 30초 이내 즉시 예측
- 🎯 **실용적 정확도**: ±30% 목표 (의사결정에 충분)
- 🖥️ **하드웨어 자동 고려**: CPU, RAM 자동 반영
- 📊 **신뢰 구간 제공**: 최소-최대 범위 표시
- 🆓 **무료 웹 서비스**: 별도 설치 불필요

---

## 3. 타겟 사용자

### 주요 페르소나

#### 페르소나 1: 데이터 분석가 (민수, 28세)
**배경:**
- 데이터 분석 경력 2년
- Python, R 사용
- 일주일에 5-10개 프로젝트 진행

**니즈:**
- "큰 데이터셋 분석할 때 시간 예측이 필요해"
- "점심 먹고 오면 끝날까? 퇴근 전에 끝날까?"
- "모델 학습 전에 대략적인 시간이라도 알고 싶어"

**사용 시나리오:**
- 100만 행 데이터로 랜덤 포레스트 학습 예정
- 점심 먹기 전 vs 퇴근 후 선택 필요
- 예측 결과: 2시간 → 점심 먹고 돌리기로 결정

---

#### 페르소나 2: 비즈니스 분석가 (지영, 32세)
**배경:**
- MBA 출신, 비전공자
- Excel, BI 도구 주로 사용
- SQL 기본 수준

**니즈:**
- "Excel로는 너무 느려서 Python을 써야 하는데..."
- "회의 전에 결과를 내야 하는데 시간이 얼마나 걸릴지 모르겠어"
- "비전공자라 경험이 없어서 감이 안 잡혀"

**사용 시나리오:**
- 50만 행 매출 데이터 분석 필요
- 오후 3시 회의까지 2시간 남음
- 예측 결과: 30분 → 지금 바로 실행하기로 결정

---

#### 페르소나 3: PM/기획자 (현우, 35세)
**배경:**
- 프로젝트 관리 경력 5년
- 기술팀 일정 관리
- 데이터 분석 직접 수행 안 함

**니즈:**
- "데이터팀에 분석 요청 전에 얼마나 걸릴지 알고 싶어"
- "일정 계획에 반영해야 해"
- "우선순위 결정 기준이 필요해"

**사용 시나리오:**
- 새 프로젝트 기획 단계
- 대용량 데이터 분석 필요성 검토
- 예측 결과: 5시간 → 하드웨어 업그레이드 또는 샘플링 고려

---

#### 페르소나 4: 학생/연구자 (수진, 24세)
**배경:**
- 대학원생 (석사)
- 논문 연구 중
- 제한된 컴퓨팅 환경

**니즈:**
- "학교 서버 대기 시간이 길어서..."
- "실험 한 번 돌리는데 얼마나 걸릴지 몰라서 계획이 안 서"
- "집 컴퓨터로 할까, 학교 서버 예약할까 고민돼"

**사용 시나리오:**
- 딥러닝 모델 학습 필요
- 집 컴퓨터(저사양) vs 학교 서버(고사양) 선택
- 예측 결과: 집(12시간) vs 학교(3시간) → 학교 서버 예약 결정

---

## 4. MVP 기능 정의

### 핵심 기능: 분석 시간 예측

#### 입력 항목
1. **데이터 정보** (필수)
   - 행 수 (rows): 숫자 입력
   - 열 수 (columns): 숫자 입력

2. **분석 방법** (필수)
   - 17개 세부 방법 선택
   - 카테고리별 그룹화:
     - 단순 집계 (3개)
     - 회귀분석 (4개)
     - 분류 (4개)
     - 클러스터링 (4개)
     - 딥러닝 (2개)

3. **사용 툴** (필수)
   - Python, R, SQL, Excel 중 선택

4. **하드웨어 성능** (선택)
   - 저사양 / 중간 / 고사양 / 최고사양
   - 미입력 시 중간 사양 기준 예측
   - CPU 코어 수, RAM 용량이 분석 시간에 큰 영향
   - 하드웨어 선택에 따라 최대 5-10배 성능 차이 발생 가능

5. **데이터 타입 정보** (선택)
   - 수치형 / 범주형 / 텍스트 비율
   - 데이터 타입에 따라 메모리 사용량 차이 발생
   - 미입력 시 일반적인 비율(수치형 70%, 범주형 30%)로 예측

#### 출력 정보
1. **예상 소요 시간** (핵심)
   - 중앙값 (가장 가능성 높은 시간)
   - 초/분/시간 단위 자동 변환

2. **신뢰 구간**
   - 최소 시간 ~ 최대 시간
   - 시각적 표시 (바 그래프)

3. **예측 신뢰도**
   - 정확도 수준 표시 (±30% 등)
   - "High", "Medium", "Low" 등급

4. **단계별 시간 분해** (부가)
   - 데이터 로딩 시간 (20%)
   - 데이터 전처리 시간 (30%)
   - 분석 실행 시간 (50%)

5. **최적화 추천** (선택적 기능)
   - 사용자가 원하는 경우에만 표시
   - 더 빠른 대안 방법 제안
   - 하드웨어 업그레이드 효과 예측
   - 데이터 샘플링 제안

### 입력 방식

#### MVP: 폼 입력 (구조화된 입력)
**장점:**
- 간단하고 빠름
- 오류 가능성 낮음
- 구현 쉬움

**구성:**
- 드롭다운 메뉴 (분석 방법, 툴, 하드웨어)
- 숫자 입력 필드 (행, 열)
- 제출 버튼

#### 향후 확장: 자연어 입력
**예시:**
- "100만 행 데이터를 랜덤 포레스트로 분석하는데 얼마나 걸려요?"
- "50만 행, 20개 컬럼, 회귀분석, 중간 사양"

---

## 5. 예측 방법론

### 기본 접근 방식

본 서비스는 **벤치마크 기반 예측**과 **메타 학습 모델**을 결합한 하이브리드 방식을 사용합니다.

#### 1. 벤치마크 데이터 기반 예측

**데이터 수집:**
- 다양한 하드웨어 환경에서 실제 분석 시간 측정
- 데이터 크기, 분석 방법, 툴, 하드웨어 사양별 벤치마크 구축
- 지속적인 데이터 수집 및 업데이트

**예측 프로세스:**
1. 사용자 입력과 유사한 벤치마크 데이터 검색
2. 가장 유사한 케이스들의 평균 시간 계산
3. 하드웨어 차이에 따른 보정 적용
4. 신뢰 구간 계산 (표준편차 기반)

**장점:**
- 실제 측정 데이터 기반으로 신뢰도 높음
- 구현이 간단하고 빠른 응답 가능
- 설명 가능한 예측 (어떤 벤치마크를 참고했는지)

#### 2. 메타 학습 모델 활용 (향후 확장)

**scitime 방식 참고:**
- 랜덤 포레스트 또는 신경망 사용
- 입력: 데이터 크기, 알고리즘 유형, 하드웨어 스펙
- 출력: 예상 시간 + 신뢰 구간

**본 서비스 적용 계획:**
- Phase 2에서 메타 학습 모델 도입 검토
- 벤치마크 데이터가 충분히 쌓인 후 (50개 이상)
- 더 정확한 예측을 위한 보완 수단으로 활용

**하이브리드 접근:**
- MVP: 벤치마크 기반 예측 (빠르고 간단)
- Phase 2+: 메타 학습 모델로 정확도 향상
- 두 방법의 결과를 결합하여 최종 예측

### 예측 정확도 목표

| Phase | 목표 정확도 | 방법론 |
|-------|-----------|-------|
| MVP (Phase 1) | ±30% | 벤치마크 기반 |
| Phase 2 | ±20% | 벤치마크 + 메타 학습 |
| Phase 3+ | ±15% | 고도화된 메타 학습 |

---

## 6. 성능 영향 요소

### 주요 영향 요소 분석

데이터 분석 시간은 다양한 요소에 의해 결정됩니다. 본 서비스는 이러한 요소들을 체계적으로 고려하여 예측합니다.

#### 1. 데이터 크기 (가장 큰 영향)

**행 수 (Rows):**
- 선형적 영향: 행이 2배 → 시간도 약 2배
- 특정 알고리즘(딥러닝)은 비선형적 증가 가능

**열 수 (Columns):**
- 중간 정도 영향
- 알고리즘에 따라 영향도 차이 (회귀분석은 큰 영향)

**파일 크기:**
- I/O 시간에 직접적 영향
- 로딩 단계에서 병목 발생 가능

#### 2. 데이터 타입 (메모리 사용량)

**영향도:**
- 수치형 (int, float): 메모리 효율적
- 범주형 (category): 최적화 가능
- 텍스트 (string): 메모리 많이 사용 (2-10배)

**예시:**
- 1백만 행 × 10열 (모두 숫자): 약 80MB
- 1백만 행 × 10열 (절반 텍스트): 약 300-500MB

**예측 반영:**
- 데이터 타입 비율에 따라 로딩 시간 보정
- 텍스트 비율 높으면 메모리 병목 경고

#### 3. 하드웨어 사양 (성능 배수)

**CPU 코어 수:**
- 병렬 처리 가능 알고리즘에 큰 영향
- 예: 랜덤 포레스트, 그리드 서치

**메모리 (RAM):**
- 데이터 전체가 메모리에 로드 가능한지 결정
- 부족 시 스왑 발생 → 시간 급증 (10배 이상)

**성능 배수:**
- 저사양 → 중간: 약 2-3배 빠름
- 중간 → 고사양: 약 2-3배 빠름
- 중간 → 최고사양: 약 4-6배 빠름

#### 4. 라이브러리/툴 선택 (5-25배 차이)

**Python 생태계:**
- Pandas: 범용적, 사용 편리
- Polars: Pandas 대비 5-25배 빠름 (Rust 기반)
- Dask: 대용량 데이터, 병렬 처리

**툴별 성능:**
- Python (Pandas): 기준 (1x)
- R (dplyr): 0.8-1.2x (비슷)
- Python (Polars): 5-25x (매우 빠름)
- SQL (DB): 데이터 크기에 따라 변동

**예측 반영:**
- MVP는 기본 라이브러리 기준 (Pandas)
- Phase 2에서 툴별 세부 옵션 추가 가능

#### 5. 데이터 전처리 복잡도

**영향 요소:**
- 결측치 비율: 높을수록 처리 시간 증가
- 인코딩 필요 여부: 범주형 → 수치형 변환
- 정규화/스케일링: 전체 데이터 스캔 필요

**예측 반영:**
- MVP에서는 평균적인 전처리 시간 가정
- Phase 2에서 전처리 복잡도 옵션 추가 가능

### 요소별 영향도 요약

| 요소 | 영향도 | 시간 변화 범위 | MVP 반영 |
|------|--------|--------------|---------|
| 데이터 크기 (행) | ⭐⭐⭐⭐⭐ | 선형 비례 | ✅ 필수 입력 |
| 데이터 크기 (열) | ⭐⭐⭐⭐ | 0.5-2배 | ✅ 필수 입력 |
| 데이터 타입 | ⭐⭐⭐ | 1-3배 | ⚠️ 선택 입력 |
| 하드웨어 사양 | ⭐⭐⭐⭐⭐ | 2-10배 | ⚠️ 선택 입력 |
| 툴/라이브러리 | ⭐⭐⭐⭐ | 1-25배 | ✅ 필수 입력 |
| 전처리 복잡도 | ⭐⭐ | 1.2-2배 | 🔜 Phase 2 |

---

## 7. 사용자 시나리오

### 시나리오 1: 점심시간 활용 (민수, 데이터 분석가)

**상황:**
- 오전 11:30, 점심 먹으러 가기 전
- 100만 행 고객 데이터로 분류 모델 학습 필요
- 점심 먹고 오면 (1시간 후) 결과가 나와있을까?

**사용 과정:**
1. 웹사이트 접속
2. 입력:
   - 행: 1,000,000
   - 열: 25
   - 방법: Random Forest (랜덤 포레스트)
   - 툴: Python
   - 하드웨어: 중간
3. "예측하기" 클릭

**결과 확인:**
```
⚡ 예측 완료 (1초 소요)

예상 소요 시간: 45분
신뢰 구간: 30분 ~ 60분 (이 범위 내에 있을 확률 70%)
신뢰도: Medium (±30%)

단계별 시간:
- 데이터 로딩: 9분
- 전처리: 14분
- 분석: 22분
```

**의사결정:**
- ✅ 점심 먹고 오면 완료될 것 같음
- ⏱️ **빠른 예측 덕분에 즉시 결정 가능**
- 지금 바로 실행하고 점심 먹으러 가기로 결정
- (최적화 추천은 보지 않음 - 시간이 충분하므로)

---

### 시나리오 2: 회의 준비 (지영, 비즈니스 분석가)

**상황:**
- 오후 1:00, 3시 회의 준비
- 50만 행 판매 데이터 피벗 분석 필요
- 회의까지 2시간, 결과를 발표해야 함

**사용 과정:**
1. 웹사이트 접속
2. 입력:
   - 행: 500,000
   - 열: 15
   - 방법: Group-by Aggregation (그룹별 집계)
   - 툴: Python
   - 하드웨어: 저사양 (노트북)
3. "예측하기" 클릭

**결과 확인:**
```
⚡ 예측 완료 (1초 소요)

예상 소요 시간: 12분
신뢰 구간: 8분 ~ 18분 (이 범위 내 확률 70%)
신뢰도: High (±20%)

💡 분석:
간단한 집계 작업으로 매우 빠르게 완료 가능합니다!
저사양 노트북으로도 충분합니다.
```

**의사결정:**
- ✅ 시간 여유 충분 (2시간 중 12분만 소요)
- ⏱️ **30초 만에 예측해서 안심하고 진행 가능**
- 지금 실행하고 자료 정리 시간 확보
- (최적화 추천은 보지 않음 - 이미 충분히 빠름)

---

### 시나리오 3: 프로젝트 기획 (현우, PM)

**상황:**
- 새 프로젝트 일정 수립 중
- 1000만 행 로그 데이터 클러스터링 필요
- 팀 리소스 및 일정 계획 필요

**사용 과정:**
1. 웹사이트 접속
2. 여러 옵션 빠르게 비교 (각 예측 1초씩, 총 3초):

**옵션 A: 현재 하드웨어**
- 입력: 10,000,000행, 30열, K-means (k>10), Python, 중간
- 결과: 5시간 30분 (3~8시간 범위)

**옵션 B: 업그레이드 하드웨어**
- 입력: 10,000,000행, 30열, K-means (k>10), Python, 고사양
- 결과: 2시간 15분 (1.5~3시간 범위)

**옵션 C: 샘플링 후 분석**
- 입력: 1,000,000행, 30열, K-means (k>10), Python, 중간
- 결과: 30분 (20~45분 범위)

**의사결정:**
- ⏱️ **3초 만에 3가지 옵션 모두 예측 완료**
- 옵션 C (샘플링) 선택
- 비용 효율적이고 일정 관리 용이
- 필요시 전체 데이터로 재분석 계획
- (최적화 추천 기능으로 샘플링 방법 확인 가능)
- (참고: 향후 최적화 추천 기능을 사용하면 대안을 자동으로 제안받을 수 있음)

---

### 시나리오 4: 연구 실험 계획 (수진, 대학원생)

**상황:**
- 논문 실험 설계 중
- 딥러닝 모델 여러 번 학습 필요
- 집 컴퓨터 vs 학교 서버 선택

**사용 과정:**
1. **집 컴퓨터 예측**
   - 입력: 200,000행, 50열, Simple Neural Network, Python, 저사양
   - ⚡ 1초 후 결과: 8시간 20분 (6~11시간 범위)

2. **학교 서버 예측**
   - 입력: 200,000행, 50열, Simple Neural Network, Python, 최고사양
   - ⚡ 1초 후 결과: 1시간 40분 (1~2.5시간 범위)

**의사결정:**
- ⏱️ **2초 만에 두 환경 비교 완료**
- 학교 서버가 5배 빠름 확인
- 학교 서버 예약 (1주일 대기)
- 하루 4번 실험 가능 → 일정 단축
- 대기 시간 동안 데이터 전처리 진행
- (GPU 사용 시 더 빠른 예측은 최적화 추천에서 확인 가능)

---

## 8. MVP 범위

### 포함되는 기능

#### 핵심 기능 (P0 - 필수)
✅ **빠른 분석 시간 예측** (핵심 가치)
- 17개 세부 분석 방법 지원
- 하드웨어 성능 자동 반영
- 신뢰 구간 제공 (항상 표시)
- 단계별 시간 분해
- **30초 이내 입력, 1초 이내 결과**

#### 입력/출력 (P0 - 필수)
✅ **간편한 입력 방식**
- 폼 기반 입력 (드롭다운 + 숫자 입력)
- 하드웨어 자동 선택 (기본값: 중간 사양)
- 데이터 타입 선택 (선택사항, 기본값 제공)

✅ **명확한 출력 정보**
- 예상 시간 (중앙값, 큰 글씨 강조)
- **신뢰 구간 (최소~최대, 항상 표시)**
- 예측 신뢰도 (High/Medium/Low)
- 단계별 분해
- 성능 영향 요소 설명

#### 데이터 지원 (P0 - 필수)
✅ **지원 데이터 유형**
- 구조화된 데이터 (CSV, Excel, DB)
- 행/열 기반 데이터

✅ **지원 분석 방법**
- 단순 집계 (3종)
- 회귀분석 (4종)
- 분류 (4종)
- 클러스터링 (4종)
- 딥러닝 (2종)

#### 선택적 기능 (P2 - MVP에 포함 가능)
⚠️ **최적화 추천 (선택사항)**
- **기본값: 숨김 처리** (사용자 혼란 방지)
- "더 빠른 방법 보기" 토글 버튼으로 활성화
- 더 빠른 대안 방법 제안
- 하드웨어 업그레이드 효과 예측
- 데이터 샘플링 제안
- **철학**: 빠른 예측이 핵심, 최적화는 부가 서비스
- 사용자 피드백 후 필요성 재검토

### 제외되는 기능 (향후 확장)

#### Phase 2 (2-3개월 후)
❌ **자연어 입력**
- "100만 행을 랜덤 포레스트로..." 형태
- AI 파싱 필요

📊 **예측 정확도 개선**
- 벤치마크 데이터 확장 (50개+)
- 메타 학습 모델 도입 검토
- 정확도 ±30% → ±20% 목표

❌ **분석 기록 저장**
- 로컬 저장 (localStorage)
- 과거 예측 이력 조회

#### Phase 3 (6개월 후)
❌ **여러 옵션 동시 비교**
- 3-4가지 옵션 나란히 비교
- 테이블 형태 출력

❌ **예측 결과 다운로드**
- PDF, Excel 내보내기
- 보고서 형태

#### Phase 4 (1년 후)
❌ **회원가입 및 개인화**
- 내 하드웨어 프로필 저장
- 자주 쓰는 설정 저장

❌ **API 제공**
- 외부 서비스 연동
- 자동화 스크립트 연동

❌ **모바일 앱**
- iOS, Android 앱

### MVP 우선순위

| 우선순위 | 기능 | 필수 여부 | 구현 난이도 | 설명 |
|--------|------|----------|-----------|------|
| P0 | 시간 예측 (17개 방법) | 필수 | 중 | 핵심 기능 |
| P0 | 하드웨어 성능 반영 | 필수 | 중 | 정확도에 중요 |
| P0 | 신뢰 구간 제공 | 필수 | 하 | 항상 표시 |
| P1 | 데이터 타입 입력 | 권장 | 하 | 메모리 예측 |
| P1 | 단계별 시간 분해 | 권장 | 하 | 투명성 제공 |
| P1 | 예측 신뢰도 표시 | 권장 | 하 | 사용자 신뢰 |
| P1 | 성능 영향 요소 설명 | 권장 | 하 | 교육적 가치 |
| P2 | 최적화 추천 (선택) | 선택 | 중 | 기본 숨김, 토글 |
| P2 | 분석 기록 저장 | 선택 | 중 | Phase 2 검토 |

**우선순위 철학:**
- **P0 (Must Have)**: "쉽고 빠른 예측"의 핵심 - MVP 출시 전 반드시 구현
- **P1 (Should Have)**: 사용자 경험 향상 - MVP에 포함하되, 시간 부족 시 간소화 가능
- **P2 (Could Have)**: 부가 서비스 - 사용자 피드백 후 결정, 기본 숨김 처리

---

## 9. 성공 지표 (KPI)

### 핵심 지표

#### 1. 사용성 지표
- **목표:** 방문자의 80% 이상이 예측 수행
- **측정:** 방문자 수 대비 예측 버튼 클릭 수

#### 2. 정확도 지표
- **목표:** 예측 정확도 ±30% 이내
- **측정:** 실제 측정 시간 대비 예측 시간 오차율

#### 3. 사용자 만족도
- **목표:** 5점 만점 4.0 이상
- **측정:** 서비스 만족도 설문 (간단한 투표)

#### 4. 재방문율
- **목표:** 월 2회 이상 재방문 50%
- **측정:** 쿠키 기반 재방문 추적

### 부가 지표

#### 5. 응답 시간
- **목표:** 1초 이내 결과 제공
- **측정:** 버튼 클릭 ~ 결과 표시 시간

#### 6. 이탈률
- **목표:** 첫 화면 이탈률 30% 이하
- **측정:** 페이지 로드 ~ 예측 수행 전 이탈

#### 7. 브라우저 호환성
- **목표:** Chrome, Edge, Safari 정상 작동
- **측정:** 브라우저별 오류 발생률

---

## 10. 향후 로드맵
```
벤치마크 레코드 = {
  rows: 행 수,
  columns: 열 수,
  method: 분석 방법,
  hardware: 하드웨어 사양,
  data_type_ratio: {numeric: 0.7, categorical: 0.2, text: 0.1},
  measured_time: 실제 측정 시간 (초),
  loading_time: 로딩 시간,
  preprocessing_time: 전처리 시간,
  execution_time: 실행 시간
}
```

#### 2. 예측 알고리즘
**현재 (MVP):**
- **유사도 기반 매칭**: 입력된 조건과 가장 유사한 벤치마크 데이터 찾기
- **선형 보간**: 유사한 벤치마크 데이터 간 보간으로 예측
- **신뢰 구간 계산**: 주변 벤치마크 데이터의 분산을 기반으로 최소~최대 범위 계산

**향후 개선 (Phase 2):**
- **메타 학습 모델**: scitime과 유사하게 랜덤 포레스트 또는 신경망 활용
- **다변수 회귀**: 데이터 크기, 하드웨어, 데이터 타입 등을 독립 변수로 회귀 분석
- **앙상블 예측**: 여러 예측 방법의 결과를 결합하여 정확도 향상

#### 3. 신뢰 구간 계산
**방법:**
- 유사한 벤치마크 데이터 (상위 5개)의 측정값 분석
- 표준편차 기반 신뢰 구간 계산
- 최소값 = 중앙값 - 1σ, 최대값 = 중앙값 + 1σ

**신뢰도 등급:**
- **High (±20%)**: 벤치마크 데이터 충분, 유사도 높음
- **Medium (±30%)**: 벤치마크 데이터 보통, 보간 필요
- **Low (±50%)**: 벤치마크 데이터 부족, 추정 범위 넓음

#### 4. 예측 정확도 향상 전략
1. **지속적 벤치마크 수집**: 사용자 피드백으로 실제 측정값 수집
2. **하드웨어 정보 정제**: CPU 코어 수, RAM 용량 등 상세 정보 활용
3. **데이터 특성 반영**: 데이터 타입 비율, 결측치 비율 등 고려
4. **캐시 효과 모델링**: 반복 실행 시 성능 향상 반영

### 메타 학습 모델 활용 가능성

**scitime 방식 적용:**
- 벤치마크 데이터를 학습 데이터로 사용
- 입력: [rows, columns, method_id, hardware_id, data_type_ratios]
- 출력: predicted_time
- 모델: Random Forest Regressor 또는 Neural Network

**장점:**
- 더 높은 예측 정확도
- 복잡한 비선형 관계 모델링
- 신뢰 구간 자동 계산 (quantile regression)

**단점:**
- 초기 벤치마크 데이터 많이 필요 (최소 100개+)
- 모델 학습 및 업데이트 필요
- MVP에서는 과도한 복잡도

**결정:** MVP는 유사도 기반 매칭 사용, Phase 2에서 메타 학습 모델 도입 검토

---

## 10. 향후 로드맵

### 1. 데이터 크기

**행 수 (Rows):**
- **영향도**: ★★★★★ (가장 큰 영향)
- 대부분의 알고리즘은 O(n) 또는 O(n log n) 복잡도
- 행 수가 2배 → 시간 2~4배 증가

**열 수 (Columns):**
- **영향도**: ★★★☆☆ (중간 영향)
- 특성 수에 따라 계산량 증가
- 차원의 저주 (고차원 데이터)
- 열 수가 2배 → 시간 1.5~2배 증가

**파일 크기:**
- **영향도**: ★★★☆☆ (로딩 단계에 영향)
- I/O 속도에 따라 로딩 시간 결정
- 압축 파일은 추가 압축 해제 시간

### 2. 데이터 타입

**수치형 (Numeric):**
- **메모리**: 8 bytes/값 (float64)
- **처리 속도**: 가장 빠름
- **영향도**: ★★☆☆☆ (기준)

**범주형 (Categorical):**
- **메모리**: 문자열 길이에 비례
- **처리 속도**: 인코딩 필요 (Label Encoding, One-Hot Encoding)
- **영향도**: ★★★☆☆ (수치형 대비 1.5~3배 느림)

**텍스트 (Text):**
- **메모리**: 매우 큼 (평균 100+ bytes/값)
- **처리 속도**: 토큰화, 벡터화 필요
- **영향도**: ★★★★☆ (수치형 대비 5~10배 느림)

**예시:**
- 100만 행 × 10열 수치형 데이터: 80 MB 메모리
- 100만 행 × 10열 범주형 데이터 (평균 10자): 100 MB 메모리
- 100만 행 × 10열 텍스트 데이터 (평균 100자): 1 GB 메모리

### 3. 하드웨어 사양

**CPU 코어 수:**
- **영향도**: ★★★★☆ (병렬화 가능한 알고리즘)
- 많은 머신러닝 라이브러리가 멀티코어 활용
- 4코어 → 8코어: 1.5~2배 빠름 (알고리즘 의존)

**메모리 용량 (RAM):**
- **영향도**: ★★★★★ (메모리 부족 시 치명적)
- 데이터가 RAM에 들어가지 않으면 디스크 스왑 발생 → 10~100배 느려짐
- 충분한 메모리: 데이터 크기의 3~5배 권장

**저장장치 (SSD vs HDD):**
- **영향도**: ★★★☆☆ (로딩 단계)
- SSD: HDD 대비 3~5배 빠른 로딩
- 분석 실행 중에는 영향 적음

**GPU:**
- **영향도**: ★★★★★ (딥러닝만 해당)
- 딥러닝: GPU 사용 시 10~100배 빠름
- 전통적 머신러닝: 거의 영향 없음

**하드웨어 사양 기준:**
```
저사양:   2코어, 4GB RAM, HDD
중간:     4코어, 8GB RAM, SSD
고사양:   8코어, 16GB RAM, SSD
최고사양: 16코어, 32GB+ RAM, SSD + GPU
```

### 4. 라이브러리 및 툴 선택

**Python 라이브러리:**
- **Pandas**: 범용, 편리함, 중간 속도 (기준)
- **Polars**: Pandas 대비 5~25배 빠름 (Rust 기반)
- **Dask**: 메모리 초과 데이터 처리 (분산 처리)
- **영향도**: ★★★★☆

**R:**
- data.table: 빠른 데이터 처리
- tidyverse: 편리하지만 느림
- **영향도**: Python Pandas와 유사

**SQL:**
- 인덱싱된 DB: 매우 빠름
- 대용량 집계에 최적화
- **영향도**: ★★★★★ (집계 작업에서 가장 빠름)

**Excel:**
- 소규모 데이터 (< 10만 행): 적합
- 대규모 데이터: 매우 느리거나 불가능
- **영향도**: ★★☆☆☆ (제한적)

### 5. 데이터 전처리 복잡도

**결측치 처리:**
- **영향도**: ★★☆☆☆
- 단순 제거: 빠름
- 보간 (interpolation): 느림 (행 수에 비례)

**인코딩:**
- **영향도**: ★★★☆☆
- Label Encoding: 빠름
- One-Hot Encoding: 열 수 폭발 → 느림

**정규화/표준화:**
- **영향도**: ★★☆☆☆
- 전체 데이터 순회 필요
- 대부분 빠른 연산

**특징 엔지니어링:**
- **영향도**: ★★★★☆ (복잡도에 따라 크게 달라짐)
- 단순 변환: 빠름
- 복잡한 계산 (날짜 파싱, 정규표현식): 매우 느림

### 6. 알고리즘 복잡도

**복잡도별 분류:**

| 알고리즘 | 시간 복잡도 | 영향도 |
|---------|-----------|--------|
| Simple Aggregation | O(n) | ★☆☆☆☆ |
| Linear Regression | O(n × m²) | ★★☆☆☆ |
| Logistic Regression | O(n × m × iterations) | ★★★☆☆ |
| K-means (k≤10) | O(n × k × iterations) | ★★★☆☆ |
| K-means (k>10) | O(n × k × iterations) | ★★★★☆ |
| Random Forest | O(n × log n × trees) | ★★★★☆ |
| Deep Learning | O(n × layers × neurons) | ★★★★★ |

**참고:**
- n: 행 수
- m: 열 수
- k: 클러스터 수
- iterations: 반복 횟수

### 영향도 요약

**시간 예측 시 고려 우선순위:**
1. **행 수** (★★★★★): 가장 큰 영향
2. **알고리즘 복잡도** (★★★★★): 두 번째로 큰 영향
3. **메모리 용량** (★★★★★): 부족 시 치명적
4. **CPU/GPU** (★★★★☆): 병렬화 가능 여부에 따라
5. **데이터 타입** (★★★☆☆): 메모리 및 전처리 시간
6. **라이브러리 선택** (★★★☆☆): 최적화 수준 차이
7. **열 수** (★★★☆☆): 고차원 데이터에서 중요
8. **전처리 복잡도** (★★☆☆☆): 작업 내용에 따라
9. **저장장치** (★★☆☆☆): 로딩 단계만 영향

---

## 9. 성공 지표 (KPI)

### 핵심 지표

#### 1. 사용성 지표
- **목표:** 방문자의 80% 이상이 예측 수행
- **측정:** 방문자 수 대비 예측 버튼 클릭 수

#### 2. 정확도 지표
- **목표:** 예측 정확도 ±30% 이내
- **측정:** 실제 측정 시간 대비 예측 시간 오차율

#### 3. 사용자 만족도
- **목표:** 5점 만점 4.0 이상
- **측정:** 서비스 만족도 설문 (간단한 투표)

#### 4. 재방문율
- **목표:** 월 2회 이상 재방문 50%
- **측정:** 쿠키 기반 재방문 추적

### 부가 지표

#### 5. 응답 시간
- **목표:** 1초 이내 결과 제공
- **측정:** 버튼 클릭 ~ 결과 표시 시간

#### 6. 이탈률
- **목표:** 첫 화면 이탈률 30% 이하
- **측정:** 페이지 로드 ~ 예측 수행 전 이탈

#### 7. 브라우저 호환성
- **목표:** Chrome, Edge, Safari 정상 작동
- **측정:** 브라우저별 오류 발생률

---

## 10. 향후 로드맵

### Phase 1: MVP 출시 (현재)
**기간:** 1-2주
**목표:** 기본 기능으로 빠르게 출시

**구현:**
- 기본 HTML 웹페이지
- 17개 분석 방법
- 하드웨어 성능 반영
- 신뢰 구간 표시

**배포:**
- GitHub Pages 무료 호스팅
- 즉시 사용 가능

---

### Phase 2: 정확도 개선 (2-3개월)
**기간:** 2-3개월
**목표:** 예측 정확도 ±30% → ±20%

**구현:**
- 벤치마크 데이터 50개 수집
- 메타 학습 모델 도입 (랜덤 포레스트 또는 신경망)
- 유사도 계산 알고리즘
- 보간법 예측

**추가 기능:**
- 예측 신뢰도 상세 표시
- 사용된 벤치마크 개수 표시
- 데이터 타입별 성능 차이 반영
- (선택) 최적화 추천 - 사용자 피드백에 따라 결정

---

### Phase 3: 고급 기능 (6개월)
**기간:** 4-6개월
**목표:** 사용자 편의성 대폭 향상

**구현:**
- 자연어 입력 지원
- 분석 기록 저장
- 여러 옵션 동시 비교
- 예측 결과 다운로드

---

### Phase 4: 확장 (1년)
**기간:** 7-12개월
**목표:** 플랫폼으로 성장

**구현:**
- 회원가입 및 개인화
- 벤치마크 데이터 100개+
- API 제공
- 모바일 앱 (선택)

---

## 11. 차별화 전략

### 핵심 차별점

#### 1. 쉬움과 빠름
**경쟁사:** 복잡한 프로파일링 도구
**우리:** 30초 입력, 1초 결과

#### 2. 실용적 정확도
**경쟁사:** 100% 정확 (실제 실행)
**우리:** 70-80% 정확 (충분히 유용)

#### 3. 하드웨어 자동 반영
**경쟁사:** 사용자가 직접 계산
**우리:** 자동 반영 및 비교

#### 4. 무료 웹 서비스
**경쟁사:** 유료 또는 복잡한 설치
**우리:** 브라우저만 있으면 즉시 사용

---

## 12. 리스크 및 대응 방안

### 주요 리스크

#### 1. 정확도 부족
**리스크:** 예측이 너무 부정확하면 신뢰 하락
**대응:**
- 신뢰 구간 명시적 표시
- "대략적 예측" 명확히 안내
- 지속적 벤치마크 데이터 수집

#### 2. 복잡한 분석 방법 처리
**리스크:** 17개 방법으로 모든 케이스 커버 불가
**대응:**
- "기타" 옵션 추가
- 가장 가까운 방법 추천
- 사용자 피드백 수집

#### 3. 하드웨어 다양성
**리스크:** 4가지 사양으로 모든 하드웨어 커버 불가
**대응:**
- 넓은 신뢰 구간 제공
- "대략적 예측" 강조
- 향후 상세 입력 옵션 추가

---

## 13. 개발 우선순위

### Must Have (P0) - 핵심 가치 구현
1. ✅ 빠른 예측 기능 (30초 입력, 1초 결과)
2. ✅ 17개 분석 방법 지원
3. ✅ 하드웨어 성능 반영
4. ✅ 신뢰 구간 항상 표시

### Should Have (P1) - 사용자 경험 향상
1. ⏳ 단계별 시간 분해
2. ⏳ 예측 신뢰도 표시 (High/Medium/Low)
3. ⏳ 성능 영향 요소 간단 설명
4. ⏳ 데이터 타입 입력 옵션

### Could Have (P2) - 선택적 부가 기능
1. 🔜 최적화 추천 (기본 숨김, 토글 가능)
2. 🔜 분석 기록 저장 (localStorage)
3. 🔜 여러 옵션 비교 UI

### Won't Have (Phase 2 이후)
1. ❌ 자연어 입력
2. ❌ 회원가입 및 개인화
3. ❌ 모바일 앱
4. ❌ API 제공

**개발 철학:**
"쉽고 빠른 예측"에 집중하고, 부가 기능은 사용자 피드백 후 결정

---

## 14. 결론

### 핵심 가치 재확인
**"쉽고 빠르게, 분석 시간을 미리 알자!"**

### MVP 성공 기준
1. ✅ 30초 이내 입력 완료 (쉬움)
2. ✅ 1초 이내 결과 제공 (빠름)
3. ✅ ±30% 이내 정확도 (실용적)
4. ✅ 사용자 만족도 4.0/5.0 (유용함)
5. ✅ 신뢰 구간 항상 표시 (투명함)

### 핵심 차별화 포인트
- ⚡ **속도**: 30초 입력, 1초 결과 - 테스트 없이 즉시 예측
- 🎯 **편의성**: 복잡한 설정 불필요 - 간단한 입력만으로 충분
- 📊 **투명성**: 신뢰 구간 항상 표시 - 예측 불확실성 명시
- 🆓 **접근성**: 무료 웹 서비스 - 설치 및 가입 불필요
- 💡 **선택성**: 최적화 추천은 선택사항 - 핵심에 집중

### 다음 단계
1. MVP 개발 완료 (이미 완료!)
2. 사용자 테스트 (5-10명)
3. 피드백 반영 (특히 최적화 추천 필요성)
4. 공개 배포 (GitHub Pages)
5. 사용자 확대 및 개선

---

**문서 작성일:** 2026년 1월
**작성자:** Project Team
**버전:** 1.1 (웹 리서치 기반 개선)

**주요 변경사항 (v1.1):**
- 기존 솔루션(scitime) 참고 추가
- 예측 방법론 상세 설명 추가
- 성능 영향 요소 분석 추가
- 데이터 타입 입력 및 메모리 영향 고려
- 신뢰 구간 강조 및 항상 표시
- 최적화 추천을 선택적 기능으로 재정의
- 사용자 시나리오에 빠른 예측 강조
