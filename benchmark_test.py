# ë°ì´í„° ë¶„ì„ ì‹œê°„ ì¸¡ì • ìŠ¤í¬ë¦½íŠ¸
# Pythonì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤!

import time
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.cluster import KMeans

def measure_analysis_time(rows, columns, analysis_type):
    """
    ì‹¤ì œ ë°ì´í„° ë¶„ì„ ì‹œê°„ì„ ì¸¡ì •í•˜ëŠ” í•¨ìˆ˜
    
    Parameters:
    - rows: ë°ì´í„° í–‰ ìˆ˜
    - columns: ë°ì´í„° ì—´ ìˆ˜
    - analysis_type: ì„¸ë¶€ ë¶„ì„ ë°©ë²• (ì˜ˆ: 'reg_linear_simple', 'clf_forest')
    """
    print(f"\n{'='*60}")
    print(f"í…ŒìŠ¤íŠ¸ ì¡°ê±´: {rows:,}í–‰ Ã— {columns}ì—´, ë¶„ì„: {analysis_type}")
    print(f"{'='*60}")
    
    # ëœë¤ ë°ì´í„° ìƒì„±
    print("1ï¸âƒ£ ë°ì´í„° ìƒì„± ì¤‘...")
    X = np.random.randn(rows, columns)
    y = np.random.randn(rows)
    
    # ì „ì²´ ì‹œì‘ ì‹œê°„
    total_start = time.time()
    
    # 1ë‹¨ê³„: ë°ì´í„° ë¡œë”© (Pandas DataFrame ë³€í™˜)
    print("2ï¸âƒ£ ë°ì´í„° ë¡œë”© ì¤‘...")
    loading_start = time.time()
    df = pd.DataFrame(X)
    loading_time = time.time() - loading_start
    
    # 2ë‹¨ê³„: ì „ì²˜ë¦¬
    print("3ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘...")
    preprocessing_start = time.time()
    # ê°„ë‹¨í•œ ì „ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    df_processed = df.copy()
    preprocessing_time = time.time() - preprocessing_start
    
    # 3ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
    print(f"4ï¸âƒ£ {analysis_type} ë¶„ì„ ì‹¤í–‰ ì¤‘...")
    analysis_start = time.time()
    
    try:
        # ë‹¨ìˆœ ì§‘ê³„
        if analysis_type == 'agg_basic':
            result = df.mean()
            result = df.sum()
            result = df.count()
        
        elif analysis_type == 'agg_groupby':
            # ì²« ë²ˆì§¸ ì—´ë¡œ ê·¸ë£¹í™”
            result = df.groupby(df.columns[0] % 10).mean()
        
        elif analysis_type == 'agg_pivot':
            df_small = df.head(min(10000, rows))  # í”¼ë²—ì€ ì‘ì€ ë°ì´í„°ë¡œ
            result = df_small.pivot_table(values=df_small.columns[0], 
                                         index=df_small.columns[1] % 5,
                                         aggfunc='mean')
        
        # íšŒê·€ë¶„ì„
        elif analysis_type == 'reg_linear_simple':
            model = LinearRegression()
            model.fit(X[:, 0:1], y)  # ë‹¨ìˆœ íšŒê·€ (1ê°œ ë³€ìˆ˜)
        
        elif analysis_type == 'reg_linear_multiple':
            model = LinearRegression()
            model.fit(X, y)  # ë‹¤ì¤‘ íšŒê·€
        
        elif analysis_type == 'reg_ridge':
            from sklearn.linear_model import Ridge
            model = Ridge(alpha=1.0, max_iter=1000)
            model.fit(X, y)
        
        elif analysis_type == 'reg_polynomial':
            from sklearn.preprocessing import PolynomialFeatures
            poly = PolynomialFeatures(degree=2)
            X_poly = poly.fit_transform(X[:, :min(5, columns)])  # 5ê°œ ì»¬ëŸ¼ë§Œ
            model = LinearRegression()
            model.fit(X_poly, y)
        
        # ë¶„ë¥˜
        elif analysis_type == 'clf_logistic':
            from sklearn.linear_model import LogisticRegression
            y_class = (y > 0).astype(int)
            model = LogisticRegression(max_iter=100)
            model.fit(X, y_class)
        
        elif analysis_type == 'clf_tree':
            from sklearn.tree import DecisionTreeClassifier
            y_class = (y > 0).astype(int)
            model = DecisionTreeClassifier(max_depth=10)
            model.fit(X, y_class)
        
        elif analysis_type == 'clf_forest':
            y_class = (y > 0).astype(int)
            model = RandomForestClassifier(n_estimators=100, max_depth=10)
            model.fit(X, y_class)
        
        elif analysis_type == 'clf_svm':
            from sklearn.svm import SVC
            y_class = (y > 0).astype(int)
            # SVMì€ ë°ì´í„°ê°€ ë§ìœ¼ë©´ ë„ˆë¬´ ëŠë ¤ì„œ ìƒ˜í”Œë§
            sample_size = min(10000, rows)
            X_sample = X[:sample_size]
            y_sample = y_class[:sample_size]
            model = SVC(kernel='rbf')
            model.fit(X_sample, y_sample)
        
        # í´ëŸ¬ìŠ¤í„°ë§
        elif analysis_type == 'clu_kmeans_small':
            model = KMeans(n_clusters=5, max_iter=300)
            model.fit(X)
        
        elif analysis_type == 'clu_kmeans_large':
            model = KMeans(n_clusters=20, max_iter=300)
            model.fit(X)
        
        elif analysis_type == 'clu_dbscan':
            from sklearn.cluster import DBSCAN
            # DBSCANì€ ë°ì´í„°ê°€ ë§ìœ¼ë©´ ìƒ˜í”Œë§
            sample_size = min(50000, rows)
            model = DBSCAN(eps=0.5, min_samples=5)
            model.fit(X[:sample_size])
        
        elif analysis_type == 'clu_hierarchical':
            from sklearn.cluster import AgglomerativeClustering
            # ê³„ì¸µì ì€ ë§¤ìš° ëŠë ¤ì„œ ì‘ì€ ìƒ˜í”Œë§Œ
            sample_size = min(5000, rows)
            model = AgglomerativeClustering(n_clusters=5)
            model.fit(X[:sample_size])
        
        # ë”¥ëŸ¬ë‹ (ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜)
        elif analysis_type == 'dl_simple':
            from sklearn.neural_network import MLPClassifier
            y_class = (y > 0).astype(int)
            model = MLPClassifier(hidden_layer_sizes=(50, 25), max_iter=10)
            model.fit(X, y_class)
        
        elif analysis_type == 'dl_deep':
            from sklearn.neural_network import MLPClassifier
            y_class = (y > 0).astype(int)
            model = MLPClassifier(hidden_layer_sizes=(100, 50, 25, 10), max_iter=20)
            model.fit(X, y_class)
        
        else:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ ë°©ë²•: {analysis_type}")
            return None
        
        analysis_time = time.time() - analysis_start
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    
    # ì „ì²´ ì‹œê°„
    total_time = time.time() - total_start
    
    # ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ… ì¸¡ì • ì™„ë£Œ!")
    print(f"\nğŸ“Š ì¸¡ì • ê²°ê³¼:")
    print(f"  â€¢ ë°ì´í„° ë¡œë”©:   {loading_time:.2f}ì´ˆ ({loading_time/total_time*100:.1f}%)")
    print(f"  â€¢ ë°ì´í„° ì „ì²˜ë¦¬: {preprocessing_time:.2f}ì´ˆ ({preprocessing_time/total_time*100:.1f}%)")
    print(f"  â€¢ ë¶„ì„ ì‹¤í–‰:     {analysis_time:.2f}ì´ˆ ({analysis_time/total_time*100:.1f}%)")
    print(f"  â€¢ ì „ì²´ ì‹œê°„:     {total_time:.2f}ì´ˆ")
    
    return {
        'rows': rows,
        'columns': columns,
        'analysis_type': analysis_type,
        'loading_time': loading_time,
        'preprocessing_time': preprocessing_time,
        'analysis_time': analysis_time,
        'total_time': total_time
    }

def compare_with_prediction(actual_time, predicted_time):
    """
    ì‹¤ì œ ì‹œê°„ê³¼ ì˜ˆì¸¡ ì‹œê°„ì„ ë¹„êµ
    """
    error = abs(actual_time - predicted_time)
    error_percent = (error / actual_time) * 100
    
    print(f"\nğŸ¯ ì •í™•ë„ ë¶„ì„:")
    print(f"  â€¢ ì‹¤ì œ ì‹œê°„:   {actual_time:.2f}ì´ˆ")
    print(f"  â€¢ ì˜ˆì¸¡ ì‹œê°„:   {predicted_time:.2f}ì´ˆ")
    print(f"  â€¢ ì˜¤ì°¨:        {error:.2f}ì´ˆ")
    print(f"  â€¢ ì˜¤ì°¨ìœ¨:      {error_percent:.1f}%")
    
    if error_percent <= 30:
        print(f"  â€¢ í‰ê°€:        âœ… ë§¤ìš° ì •í™•! (ëª©í‘œ: Â±30% ì´ë‚´)")
    elif error_percent <= 50:
        print(f"  â€¢ í‰ê°€:        âš ï¸ ì–‘í˜¸ (Â±50% ì´ë‚´)")
    else:
        print(f"  â€¢ í‰ê°€:        âŒ ê°œì„  í•„ìš” (Â±50% ì´ˆê³¼)")
    
    return error_percent

# ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    print("=" * 60)
    print("ë°ì´í„° ë¶„ì„ ì‹œê°„ ì¸¡ì • ë„êµ¬")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤ (ì„¸ë¶€ ë°©ë²•)
    test_cases = [
        {'rows': 10000, 'columns': 10, 'analysis': 'agg_basic', 'name': 'ê¸°ë³¸ ì§‘ê³„'},
        {'rows': 100000, 'columns': 20, 'analysis': 'reg_linear_multiple', 'name': 'ë‹¤ì¤‘ ì„ í˜• íšŒê·€'},
        {'rows': 50000, 'columns': 15, 'analysis': 'clf_tree', 'name': 'ì˜ì‚¬ê²°ì •ë‚˜ë¬´'},
        {'rows': 100000, 'columns': 20, 'analysis': 'clf_forest', 'name': 'ëœë¤ í¬ë ˆìŠ¤íŠ¸'},
        {'rows': 50000, 'columns': 10, 'analysis': 'clu_kmeans_small', 'name': 'K-means (k=5)'},
    ]
    
    print("\nğŸ’¡ í…ŒìŠ¤íŠ¸í•  ì¡°ê±´ì„ ì„ íƒí•˜ì„¸ìš”:")
    for i, case in enumerate(test_cases, 1):
        print(f"{i}. {case['name']} ({case['rows']:,}í–‰ Ã— {case['columns']}ì—´)")
    print(f"{len(test_cases)+1}. ì‚¬ìš©ì ì •ì˜")
    
    choice = input(f"\nì„ íƒ (1-{len(test_cases)+1}): ").strip()
    
    if choice == str(len(test_cases)+1):
        # ì‚¬ìš©ì ì •ì˜ ì…ë ¥
        rows = int(input("ë°ì´í„° í–‰ ìˆ˜: "))
        columns = int(input("ë°ì´í„° ì—´ ìˆ˜: "))
        print("\në¶„ì„ ë°©ë²• ì˜ˆì‹œ:")
        print("  ì§‘ê³„: agg_basic, agg_groupby, agg_pivot")
        print("  íšŒê·€: reg_linear_simple, reg_linear_multiple, reg_ridge, reg_polynomial")
        print("  ë¶„ë¥˜: clf_logistic, clf_tree, clf_forest, clf_svm")
        print("  í´ëŸ¬ìŠ¤í„°ë§: clu_kmeans_small, clu_kmeans_large, clu_dbscan")
        print("  ë”¥ëŸ¬ë‹: dl_simple, dl_deep")
        analysis = input("\në¶„ì„ ë°©ë²• ì„ íƒ: ").strip()
    elif choice.isdigit() and 1 <= int(choice) <= len(test_cases):
        test_case = test_cases[int(choice) - 1]
        rows = test_case['rows']
        columns = test_case['columns']
        analysis = test_case['analysis']
    else:
        print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        rows, columns, analysis = 10000, 10, 'agg_basic'
    
    # ì‹¤ì œ ì‹œê°„ ì¸¡ì •
    result = measure_analysis_time(rows, columns, analysis)
    
    if result:
        print(f"\nğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"\nğŸ“ ì´ì œ ì›¹í˜ì´ì§€(index.html)ì—ì„œ ê°™ì€ ì¡°ê±´ìœ¼ë¡œ ì˜ˆì¸¡í•´ë³´ì„¸ìš”:")
        print(f"   - ë°ì´í„° í–‰ ìˆ˜: {rows:,}")
        print(f"   - ë°ì´í„° ì—´ ìˆ˜: {columns}")
        print(f"   - ë¶„ì„ ë°©ë²•: {analysis}")
        print(f"   - ì‚¬ìš© íˆ´: Python")
        
        print(f"\nê·¸ëŸ° ë‹¤ìŒ ì˜ˆì¸¡ëœ ì‹œê°„ì„ ì…ë ¥í•˜ì„¸ìš”:")
        predicted = float(input("ì˜ˆì¸¡ ì‹œê°„ (ì´ˆ): "))
        
        compare_with_prediction(result['total_time'], predicted)
