"""
ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ (scitime ë°©ì‹)
ëžœë¤ í¬ë ˆìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•œ ë©”íƒ€ í•™ìŠµìœ¼ë¡œ ë¶„ì„ ì‹œê°„ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

import json
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from typing import Dict, Any, List
import pickle


class MLTimePredictor:
    """scitime ë°©ì‹ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì‹œê°„ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self):
        self.model = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        self.method_encoder = LabelEncoder()
        self.hardware_encoder = LabelEncoder()
        self.is_trained = False
        
        # ì•Œê³ ë¦¬ì¦˜ê³¼ í•˜ë“œì›¨ì–´ ì¹´í…Œê³ ë¦¬ ë¯¸ë¦¬ ì •ì˜
        self.known_methods = [
            'agg_basic', 'agg_groupby', 'agg_pivot',
            'reg_linear_simple', 'reg_linear_multiple', 'reg_ridge', 'reg_polynomial',
            'clf_logistic', 'clf_tree', 'clf_forest', 'clf_svm',
            'clu_kmeans_small', 'clu_kmeans_large', 'clu_dbscan', 'clu_hierarchical',
            'dl_simple', 'dl_deep'
        ]
        self.known_hardware = ['low', 'medium', 'high', 'ultra']
    
    def train(self, benchmark_file='benchmark_data.json'):
        """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ"""
        print("\n" + "=" * 60)
        print("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ì‹œìž‘ (scitime ë°©ì‹)")
        print("=" * 60)
        
        # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ
        try:
            with open(benchmark_file, 'r', encoding='utf-8') as f:
                benchmarks = json.load(f)
        except FileNotFoundError:
            print(f"âŒ {benchmark_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        if len(benchmarks) == 0:
            print("âŒ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print(f"ðŸ“Š {len(benchmarks)}ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ")
        
        # ì¸ì½”ë” ë¨¼ì € í•™ìŠµ
        self.method_encoder.fit(self.known_methods)
        self.hardware_encoder.fit(self.known_hardware)
        
        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì¤€ë¹„
        X = self._prepare_features(benchmarks)
        y = np.log([b['elapsed_time_seconds'] + 1e-10 for b in benchmarks])  # log scale
        
        # ëª¨ë¸ í•™ìŠµ
        print("ðŸ§  ëžœë¤ í¬ë ˆìŠ¤íŠ¸ ëª¨ë¸ í•™ìŠµ ì¤‘...")
        self.model.fit(X, y)
        self.is_trained = True
        
        # í•™ìŠµ ì„±ëŠ¥ í‰ê°€
        train_score = self.model.score(X, y)
        y_pred = self.model.predict(X)
        
        # ì‹¤ì œ ì‹œê°„ ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ ì˜¤ì°¨ ê³„ì‚°
        y_actual = np.exp(y)
        y_pred_actual = np.exp(y_pred)
        
        errors = np.abs(y_pred_actual - y_actual) / y_actual * 100
        mean_error = np.mean(errors)
        median_error = np.median(errors)
        
        print(f"âœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"   RÂ² Score: {train_score:.3f}")
        print(f"   í‰ê·  ì˜¤ì°¨: Â±{mean_error:.1f}%")
        print(f"   ì¤‘ì•™ê°’ ì˜¤ì°¨: Â±{median_error:.1f}%")
        
        # íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥
        feature_names = self._get_feature_names()
        importances = self.model.feature_importances_
        
        print(f"\nðŸ“ˆ íŠ¹ì„± ì¤‘ìš”ë„ (Top 5):")
        importance_pairs = sorted(zip(feature_names, importances), 
                                 key=lambda x: x[1], reverse=True)
        for name, importance in importance_pairs[:5]:
            print(f"   {name}: {importance:.3f}")
        
        return True
    
    def _prepare_features(self, data: List[Dict]) -> np.ndarray:
        """íŠ¹ì„± ë²¡í„° ì¤€ë¹„"""
        features = []
        
        for item in data:
            # ë¡œê·¸ ìŠ¤ì¼€ì¼ íŠ¹ì„±
            log_rows = np.log10(item['rows'] + 1)
            log_cols = np.log10(item['columns'] + 1)
            
            # ì•Œê³ ë¦¬ì¦˜ ì¸ì½”ë”©
            method = item['method']
            if method in self.known_methods:
                method_encoded = self.method_encoder.transform([method])[0]
            else:
                method_encoded = -1  # ì•Œ ìˆ˜ ì—†ëŠ” ì•Œê³ ë¦¬ì¦˜
            
            # í•˜ë“œì›¨ì–´ ì¸ì½”ë”©
            hardware = item['hardware']
            if hardware in self.known_hardware:
                hardware_encoded = self.hardware_encoder.transform([hardware])[0]
            else:
                hardware_encoded = 1  # ê¸°ë³¸ê°’ medium
            
            # ë°ì´í„° íƒ€ìž… ë¹„ìœ¨
            data_type = item.get('data_type_ratio', {})
            numeric_ratio = data_type.get('numeric', 0.7)
            categorical_ratio = data_type.get('categorical', 0.2)
            text_ratio = data_type.get('text', 0.1)
            
            # íŠ¹ì„± ë²¡í„° êµ¬ì„±
            feature_vector = [
                log_rows,
                log_cols,
                method_encoded,
                hardware_encoded,
                numeric_ratio,
                categorical_ratio,
                text_ratio,
                log_rows * log_cols,  # ìƒí˜¸ìž‘ìš© íŠ¹ì„±
                log_rows * method_encoded,  # ìƒí˜¸ìž‘ìš© íŠ¹ì„±
            ]
            
            features.append(feature_vector)
        
        return np.array(features)
    
    def _get_feature_names(self) -> List[str]:
        """íŠ¹ì„± ì´ë¦„ ëª©ë¡"""
        return [
            'log_rows',
            'log_cols',
            'method_encoded',
            'hardware_encoded',
            'numeric_ratio',
            'categorical_ratio',
            'text_ratio',
            'rows_x_cols',
            'rows_x_method'
        ]
    
    def predict(self, user_input: Dict[str, Any]) -> Dict[str, Any]:
        """ì‚¬ìš©ìž ìž…ë ¥ì— ëŒ€í•œ ì‹œê°„ ì˜ˆì¸¡"""
        if not self.is_trained:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
        
        # íŠ¹ì„± ì¤€ë¹„
        X = self._prepare_features([user_input])
        
        # ì˜ˆì¸¡ (log scale)
        log_time_pred = self.model.predict(X)[0]
        
        # ì‹¤ì œ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
        predicted_time = np.exp(log_time_pred)
        
        # ì‹ ë¢° êµ¬ê°„ ì¶”ì • (ëžœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ ê°œë³„ íŠ¸ë¦¬ ì˜ˆì¸¡ ì‚¬ìš©)
        tree_predictions = []
        for estimator in self.model.estimators_:
            tree_pred = estimator.predict(X)[0]
            tree_predictions.append(np.exp(tree_pred))
        
        # ë°±ë¶„ìœ„ìˆ˜ë¡œ ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
        percentile_25 = np.percentile(tree_predictions, 25)
        percentile_75 = np.percentile(tree_predictions, 75)
        
        # ë³´ìˆ˜ì ìœ¼ë¡œ í™•ìž¥
        min_time = percentile_25 * 0.7
        max_time = percentile_75 * 1.3
        
        # ì‹ ë¢°ë„ ê³„ì‚°
        std_dev = np.std(tree_predictions)
        cv = std_dev / predicted_time if predicted_time > 0 else 1.0
        
        if cv < 0.25:
            confidence_level = "High"
            confidence_percent = 20
        elif cv < 0.4:
            confidence_level = "Medium"
            confidence_percent = 30
        else:
            confidence_level = "Low"
            confidence_percent = 40
        
        # ë‹¨ê³„ë³„ ë¶„í•´
        breakdown = {
            'loading_minutes': round(predicted_time * 0.2 / 60, 2),
            'preprocessing_minutes': round(predicted_time * 0.3 / 60, 2),
            'execution_minutes': round(predicted_time * 0.5 / 60, 2)
        }
        
        return {
            'estimated_time_minutes': round(predicted_time / 60, 2),
            'confidence_interval': {
                'min_minutes': round(min_time / 60, 2),
                'max_minutes': round(max_time / 60, 2)
            },
            'confidence_level': confidence_level,
            'confidence_percent': confidence_percent,
            'breakdown': breakdown,
            'data_source': 'ml_model'
        }
    
    def save_model(self, filename='ml_model.pkl'):
        """í•™ìŠµëœ ëª¨ë¸ ì €ìž¥"""
        if not self.is_trained:
            print("âš ï¸  í•™ìŠµë˜ì§€ ì•Šì€ ëª¨ë¸ì€ ì €ìž¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        model_data = {
            'model': self.model,
            'method_encoder': self.method_encoder,
            'hardware_encoder': self.hardware_encoder,
            'known_methods': self.known_methods,
            'known_hardware': self.known_hardware,
            'is_trained': self.is_trained
        }
        
        with open(filename, 'wb') as f:
            pickle.dump(model_data, f)
        
        print(f"ðŸ’¾ ëª¨ë¸ì„ '{filename}'ì— ì €ìž¥í–ˆìŠµë‹ˆë‹¤.")
        return True
    
    def load_model(self, filename='ml_model.pkl'):
        """ì €ìž¥ëœ ëª¨ë¸ ë¡œë“œ"""
        try:
            with open(filename, 'rb') as f:
                model_data = pickle.load(f)
            
            self.model = model_data['model']
            self.method_encoder = model_data['method_encoder']
            self.hardware_encoder = model_data['hardware_encoder']
            self.known_methods = model_data['known_methods']
            self.known_hardware = model_data['known_hardware']
            self.is_trained = model_data['is_trained']
            
            print(f"âœ… '{filename}'ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            return True
        except FileNotFoundError:
            print(f"âŒ '{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return False


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    predictor = MLTimePredictor()
    
    # ëª¨ë¸ í•™ìŠµ
    if predictor.train('benchmark_data.json'):
        # ëª¨ë¸ ì €ìž¥
        predictor.save_model()
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
        print("\n" + "=" * 60)
        print("ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
        print("=" * 60)
        
        test_cases = [
            {
                'rows': 1000000,
                'columns': 50,
                'method': 'clf_forest',
                'hardware': 'medium',
                'data_type_ratio': {'numeric': 0.7, 'categorical': 0.2, 'text': 0.1}
            },
            {
                'rows': 100000,
                'columns': 20,
                'method': 'reg_linear_multiple',
                'hardware': 'low',
                'data_type_ratio': {'numeric': 0.8, 'categorical': 0.15, 'text': 0.05}
            },
            {
                'rows': 50000,
                'columns': 15,
                'method': 'clf_svm',
                'hardware': 'high',
                'data_type_ratio': {'numeric': 0.6, 'categorical': 0.3, 'text': 0.1}
            }
        ]
        
        for i, test_input in enumerate(test_cases, 1):
            print(f"\nðŸ“Š í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}:")
            print(f"   ë°ì´í„°: {test_input['rows']:,} í–‰ Ã— {test_input['columns']} ì—´")
            print(f"   ë°©ë²•: {test_input['method']}")
            print(f"   í•˜ë“œì›¨ì–´: {test_input['hardware']}")
            
            result = predictor.predict(test_input)
            
            print(f"\n   â±ï¸  ì˜ˆìƒ ì‹œê°„: {result['estimated_time_minutes']} ë¶„")
            print(f"   ðŸ“Š ì‹ ë¢° êµ¬ê°„: {result['confidence_interval']['min_minutes']} ~ "
                  f"{result['confidence_interval']['max_minutes']} ë¶„")
            print(f"   ðŸŽ¯ ì‹ ë¢°ë„: {result['confidence_level']} (Â±{result['confidence_percent']}%)")
            print(f"   ðŸ” ë°ì´í„° ì¶œì²˜: {result['data_source']}")
        
        print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
