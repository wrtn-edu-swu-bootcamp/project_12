"""
ë¶„ì„ ì‹œê°„ ì˜ˆì¸¡ ì—”ì§„
ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
ML ëª¨ë¸ê³¼ ì•™ìƒë¸” ì˜ˆì¸¡ì„ ì§€ì›í•©ë‹ˆë‹¤.
"""

import json
import numpy as np
from typing import Dict, List, Any


class TimePredictor:
    """ë¶„ì„ ì‹œê°„ ì˜ˆì¸¡ê¸° (ë²¤ì¹˜ë§ˆí¬ + ML ì•™ìƒë¸”)"""
    
    def __init__(self, benchmark_file='benchmark_data.json', use_ml=True):
        """
        Args:
            benchmark_file: ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° JSON íŒŒì¼ ê²½ë¡œ
            use_ml: ML ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
        """
        self.benchmarks = []
        self.load_benchmarks(benchmark_file)
        self.use_ml = use_ml
        self.ml_predictor = None
        
        # ML ëª¨ë¸ ë¡œë“œ ì‹œë„
        if use_ml:
            try:
                from ml_predictor import MLTimePredictor
                self.ml_predictor = MLTimePredictor()
                
                # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì‹œë„
                if not self.ml_predictor.load_model('ml_model.pkl'):
                    # ì—†ìœ¼ë©´ í•™ìŠµ
                    print("ğŸ’¡ ML ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤...")
                    if self.ml_predictor.train(benchmark_file):
                        self.ml_predictor.save_model('ml_model.pkl')
            except Exception as e:
                print(f"âš ï¸  ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                print("   ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜ ì˜ˆì¸¡ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.ml_predictor = None
    
    def load_benchmarks(self, filename):
        """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° ë¡œë“œ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                self.benchmarks = json.load(f)
            print(f"âœ… {len(self.benchmarks)}ê°œì˜ ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except FileNotFoundError:
            print(f"âš ï¸  '{filename}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("   data_fetcher.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            self.benchmarks = []
        except Exception as e:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            self.benchmarks = []
    
    def predict(self, user_input: Dict[str, Any], use_ensemble=True) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì…ë ¥ì— ëŒ€í•œ ë¶„ì„ ì‹œê°„ ì˜ˆì¸¡ (ì•™ìƒë¸” ì§€ì›)
        
        Args:
            user_input: {
                'rows': int,
                'columns': int,
                'method': str,
                'tool': str,
                'hardware': str,
                'data_type_ratio': dict (optional)
            }
            use_ensemble: ì•™ìƒë¸” ì˜ˆì¸¡ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’ True)
        
        Returns:
            {
                'estimated_time_minutes': float,
                'confidence_interval': {'min': float, 'max': float},
                'confidence_level': str,
                'breakdown': {...},
                'similar_cases_count': int,
                'data_source': str
            }
        """
        # ML ëª¨ë¸ì´ ìˆê³  ì•™ìƒë¸”ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
        if use_ensemble and self.ml_predictor and self.ml_predictor.is_trained:
            return self._ensemble_predict(user_input)
        
        # ì¼ë°˜ ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜ ì˜ˆì¸¡
        if not self.benchmarks:
            return self._fallback_prediction(user_input)
        
        # 1. ìœ ì‚¬í•œ ì¼€ì´ìŠ¤ ì°¾ê¸°
        similar_cases = self._find_similar_cases(user_input)
        
        if len(similar_cases) < 3:
            # ìœ ì‚¬ ì¼€ì´ìŠ¤ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ë” ë„“ê²Œ ê²€ìƒ‰
            similar_cases = self._find_similar_cases(user_input, tolerance=2.0)
        
        if len(similar_cases) < 1:
            # ê·¸ë˜ë„ ì—†ìœ¼ë©´ í´ë°±
            return self._fallback_prediction(user_input)
        
        # 2. ì˜ˆì¸¡ ê³„ì‚°
        times = [case['elapsed_time_seconds'] for case in similar_cases]
        median_time = np.median(times)
        
        # 3. ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
        percentile_25 = np.percentile(times, 25)
        percentile_75 = np.percentile(times, 75)
        
        # ìµœì†Œ/ìµœëŒ€ ë²”ìœ„ (ë³´ìˆ˜ì ìœ¼ë¡œ)
        min_time = max(percentile_25 * 0.7, min(times) * 0.9)
        max_time = min(percentile_75 * 1.3, max(times) * 1.1)
        
        # 4. ì‹ ë¢°ë„ ê³„ì‚°
        confidence_level = self._calculate_confidence(similar_cases, user_input)
        
        # 5. ë‹¨ê³„ë³„ ë¶„í•´
        breakdown = {
            'loading_minutes': round(median_time * 0.2 / 60, 2),
            'preprocessing_minutes': round(median_time * 0.3 / 60, 2),
            'execution_minutes': round(median_time * 0.5 / 60, 2)
        }
        
        return {
            'estimated_time_minutes': round(median_time / 60, 2),
            'confidence_interval': {
                'min_minutes': round(min_time / 60, 2),
                'max_minutes': round(max_time / 60, 2)
            },
            'confidence_level': confidence_level,
            'breakdown': breakdown,
            'similar_cases_count': len(similar_cases),
            'data_source': 'benchmark' if similar_cases else 'fallback'
        }
    
    def _find_similar_cases(self, user_input: Dict[str, Any], tolerance=1.5) -> List[Dict]:
        """ìœ ì‚¬í•œ ë²¤ì¹˜ë§ˆí¬ ì¼€ì´ìŠ¤ ì°¾ê¸°"""
        similar = []
        
        target_rows = user_input['rows']
        target_cols = user_input['columns']
        target_method = user_input['method']
        target_hardware = user_input['hardware']
        
        for benchmark in self.benchmarks:
            # 1. ë¶„ì„ ë°©ë²•ì´ ê°™ì•„ì•¼ í•¨
            if benchmark['method'] != target_method:
                continue
            
            # 2. í•˜ë“œì›¨ì–´ê°€ ê°™ì•„ì•¼ í•¨
            if benchmark['hardware'] != target_hardware:
                continue
            
            # 3. ë°ì´í„° í¬ê¸°ê°€ ìœ ì‚¬í•´ì•¼ í•¨ (tolerance ë°° ì´ë‚´)
            row_ratio = benchmark['rows'] / target_rows
            col_ratio = benchmark['columns'] / target_cols
            
            if (1/tolerance <= row_ratio <= tolerance and 
                1/tolerance <= col_ratio <= tolerance):
                
                # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚° (í¬ê¸°ê°€ ë¹„ìŠ·í• ìˆ˜ë¡ ë†’ìŒ)
                similarity = 1 / (abs(np.log(row_ratio)) + abs(np.log(col_ratio)) + 1)
                benchmark['similarity'] = similarity
                similar.append(benchmark)
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        similar.sort(key=lambda x: x['similarity'], reverse=True)
        
        # ìƒìœ„ 10ê°œë§Œ ì‚¬ìš©
        return similar[:10]
    
    def _ensemble_predict(self, user_input: Dict[str, Any]) -> Dict[str, Any]:
        """ì•™ìƒë¸” ì˜ˆì¸¡: ë²¤ì¹˜ë§ˆí¬ + ML + ë³µì¡ë„ ê¸°ë°˜"""
        predictions = []
        weights = []
        
        # 1. ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜ ì˜ˆì¸¡
        benchmark_result = None
        similar_cases = self._find_similar_cases(user_input)
        if len(similar_cases) < 3:
            similar_cases = self._find_similar_cases(user_input, tolerance=2.0)
        
        if len(similar_cases) >= 1:
            times = [case['elapsed_time_seconds'] for case in similar_cases]
            benchmark_time = np.median(times)
            predictions.append(benchmark_time)
            # ìœ ì‚¬ ì¼€ì´ìŠ¤ê°€ ë§ì„ìˆ˜ë¡ ê°€ì¤‘ì¹˜ ë†’ìŒ
            weight = min(len(similar_cases) / 10.0, 1.0)
            weights.append(weight * 0.5)  # ìµœëŒ€ 50% ê°€ì¤‘ì¹˜
            benchmark_result = {
                'time': benchmark_time,
                'count': len(similar_cases),
                'confidence': self._calculate_confidence(similar_cases, user_input)
            }
        
        # 2. ML ëª¨ë¸ ì˜ˆì¸¡
        ml_result = None
        try:
            ml_prediction = self.ml_predictor.predict(user_input)
            ml_time = ml_prediction['estimated_time_minutes'] * 60  # ì´ˆë¡œ ë³€í™˜
            predictions.append(ml_time)
            weights.append(0.4)  # 40% ê°€ì¤‘ì¹˜
            ml_result = ml_prediction
        except Exception as e:
            print(f"âš ï¸  ML ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
        
        # 3. ë³µì¡ë„ ê¸°ë°˜ ì˜ˆì¸¡
        fallback_result = self._fallback_prediction(user_input)
        fallback_time = fallback_result['estimated_time_minutes'] * 60
        predictions.append(fallback_time)
        weights.append(0.1)  # 10% ê°€ì¤‘ì¹˜
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        if len(predictions) == 0:
            return fallback_result
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(weights)
        normalized_weights = [w / total_weight for w in weights]
        
        # ìµœì¢… ì˜ˆì¸¡
        final_time = sum(p * w for p, w in zip(predictions, normalized_weights))
        
        # ì‹ ë¢° êµ¬ê°„ ê³„ì‚° (ì˜ˆì¸¡ê°’ë“¤ì˜ ë¶„ì‚° ê¸°ë°˜)
        if len(predictions) > 1:
            std_dev = np.std(predictions)
            min_time = max(final_time - 1.5 * std_dev, min(predictions) * 0.7)
            max_time = min(final_time + 1.5 * std_dev, max(predictions) * 1.3)
        else:
            min_time = final_time * 0.7
            max_time = final_time * 1.3
        
        # ì‹ ë¢°ë„ ê²°ì •
        if benchmark_result and benchmark_result['count'] >= 5:
            confidence_level = benchmark_result['confidence']
            confidence_percent = 20 if confidence_level == 'High' else 25 if confidence_level == 'Medium' else 35
        elif ml_result:
            confidence_level = ml_result.get('confidence_level', 'Medium')
            confidence_percent = ml_result.get('confidence_percent', 25)
        else:
            confidence_level = 'Medium'
            confidence_percent = 30
        
        # ë‹¨ê³„ë³„ ë¶„í•´
        breakdown = {
            'loading_minutes': round(final_time * 0.2 / 60, 2),
            'preprocessing_minutes': round(final_time * 0.3 / 60, 2),
            'execution_minutes': round(final_time * 0.5 / 60, 2)
        }
        
        return {
            'estimated_time_minutes': round(final_time / 60, 2),
            'confidence_interval': {
                'min_minutes': round(min_time / 60, 2),
                'max_minutes': round(max_time / 60, 2)
            },
            'confidence_level': confidence_level,
            'breakdown': breakdown,
            'similar_cases_count': benchmark_result['count'] if benchmark_result else 0,
            'data_source': 'ensemble',
            'ensemble_details': {
                'benchmark_used': benchmark_result is not None,
                'ml_used': ml_result is not None,
                'weights': {
                    'benchmark': normalized_weights[0] if len(normalized_weights) > 0 else 0,
                    'ml': normalized_weights[1] if len(normalized_weights) > 1 else 0,
                    'complexity': normalized_weights[-1]
                }
            }
        }
    
    def _calculate_confidence(self, similar_cases: List[Dict], user_input: Dict) -> str:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        if len(similar_cases) == 0:
            return "Low"
        
        # ì¼€ì´ìŠ¤ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        if len(similar_cases) >= 5:
            # ë°ì´í„° ë³€ë™ì„± í™•ì¸
            times = [case['elapsed_time_seconds'] for case in similar_cases]
            std_dev = np.std(times)
            mean_time = np.mean(times)
            cv = std_dev / mean_time if mean_time > 0 else 1.0  # ë³€ë™ê³„ìˆ˜
            
            if cv < 0.3:
                return "High"
            elif cv < 0.5:
                return "Medium"
            else:
                return "Low"
        elif len(similar_cases) >= 3:
            return "Medium"
        else:
            return "Low"
    
    def _fallback_prediction(self, user_input: Dict[str, Any]) -> Dict[str, Any]:
        """ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ê°€ ì—†ì„ ë•Œ ë³µì¡ë„ ê¸°ë°˜ ì˜ˆì¸¡"""
        rows = user_input['rows']
        cols = user_input['columns']
        method = user_input['method']
        hardware = user_input['hardware']
        
        # í•˜ë“œì›¨ì–´ ë°°ìœ¨
        hw_multiplier = {
            'low': 4.0,
            'medium': 1.0,
            'high': 0.4,
            'ultra': 0.2
        }.get(hardware, 1.0)
        
        # ì•Œê³ ë¦¬ì¦˜ë³„ ë³µì¡ë„ ê¸°ë°˜ ì‹œê°„ ì¶”ì • (ì´ˆ)
        if method.startswith('agg_'):
            base_time = rows * cols * 1e-7
        elif method.startswith('reg_'):
            base_time = rows * cols * cols * 1e-6
        elif method == 'clf_logistic':
            base_time = rows * cols * 100 * 1e-6
        elif method == 'clf_tree':
            base_time = rows * np.log(rows) * cols * 2e-6
        elif method == 'clf_forest':
            base_time = rows * np.log(rows) * cols * 100 * 2e-6
        elif method == 'clf_svm':
            base_time = rows * rows * cols * 1e-8
        elif method.startswith('clu_kmeans'):
            k = 5 if 'small' in method else 15
            base_time = rows * k * cols * 100 * 1e-6
        elif method == 'clu_dbscan':
            base_time = rows * rows * 1e-7
        elif method == 'clu_hierarchical':
            base_time = rows * rows * 1e-7
        elif method.startswith('dl_'):
            base_time = rows * cols * 1000 * 1e-5
        else:
            base_time = rows * cols * 1e-6
        
        # í•˜ë“œì›¨ì–´ ë³´ì •
        estimated_time = base_time * hw_multiplier
        
        # ì‹ ë¢° êµ¬ê°„ (Â±40%)
        min_time = estimated_time * 0.6
        max_time = estimated_time * 1.4
        
        return {
            'estimated_time_minutes': round(estimated_time / 60, 2),
            'confidence_interval': {
                'min_minutes': round(min_time / 60, 2),
                'max_minutes': round(max_time / 60, 2)
            },
            'confidence_level': 'Low',
            'breakdown': {
                'loading_minutes': round(estimated_time * 0.2 / 60, 2),
                'preprocessing_minutes': round(estimated_time * 0.3 / 60, 2),
                'execution_minutes': round(estimated_time * 0.5 / 60, 2)
            },
            'similar_cases_count': 0,
            'data_source': 'complexity_based'
        }
    
    def get_optimization_suggestions(self, user_input: Dict[str, Any], 
                                     prediction: Dict[str, Any]) -> List[str]:
        """ìµœì í™” ì œì•ˆ ìƒì„±"""
        suggestions = []
        
        estimated_minutes = prediction['estimated_time_minutes']
        
        # ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ê²½ìš°ì—ë§Œ ì œì•ˆ
        if estimated_minutes < 5:
            return []
        
        # í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ
        if user_input['hardware'] in ['low', 'medium']:
            suggestions.append(
                f"ğŸ’» í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ ì‹œ {estimated_minutes * 0.4:.1f}~"
                f"{estimated_minutes * 0.25:.1f}ë¶„ìœ¼ë¡œ ë‹¨ì¶• ê°€ëŠ¥"
            )
        
        # ìƒ˜í”Œë§ ì œì•ˆ
        if user_input['rows'] > 100000:
            sampled_time = estimated_minutes * 0.1
            suggestions.append(
                f"ğŸ”¬ 10% ìƒ˜í”Œë§ ì‚¬ìš© ì‹œ ì•½ {sampled_time:.1f}ë¶„ìœ¼ë¡œ ë‹¨ì¶•"
            )
        
        # ì•Œê³ ë¦¬ì¦˜ ë³€ê²½
        if user_input['method'] == 'clf_svm' and user_input['rows'] > 10000:
            suggestions.append(
                "âš¡ SVM ëŒ€ì‹  ëœë¤ í¬ë ˆìŠ¤íŠ¸ ì‚¬ìš© ì‹œ 5-10ë°° ë¹ ë¦„"
            )
        
        if user_input['method'] == 'clf_forest':
            suggestions.append(
                "ğŸŒ² ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¸ë¦¬ ê°œìˆ˜ë¥¼ 50ê°œë¡œ ì¤„ì´ë©´ 2ë°° ë¹ ë¦„"
            )
        
        # íˆ´ ë³€ê²½
        if user_input['tool'] == 'python' and user_input['method'].startswith('agg_'):
            suggestions.append(
                "ğŸš€ Python ëŒ€ì‹  SQL ì‚¬ìš© ì‹œ 2-5ë°° ë¹ ë¦„ (ì§‘ê³„ ì‘ì—…)"
            )
        
        return suggestions[:3]  # ìµœëŒ€ 3ê°œë§Œ


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    predictor = TimePredictor('benchmark_data.json')
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        {
            'rows': 1000000,
            'columns': 50,
            'method': 'clf_forest',
            'tool': 'python',
            'hardware': 'medium'
        },
        {
            'rows': 100000,
            'columns': 20,
            'method': 'reg_linear_multiple',
            'tool': 'python',
            'hardware': 'low'
        },
        {
            'rows': 10000,
            'columns': 10,
            'method': 'agg_basic',
            'tool': 'python',
            'hardware': 'high'
        }
    ]
    
    print("\n" + "=" * 60)
    print("ì˜ˆì¸¡ ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    for i, test_input in enumerate(test_cases, 1):
        print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}:")
        print(f"   ë°ì´í„°: {test_input['rows']:,} í–‰ Ã— {test_input['columns']} ì—´")
        print(f"   ë°©ë²•: {test_input['method']}")
        print(f"   í•˜ë“œì›¨ì–´: {test_input['hardware']}")
        
        prediction = predictor.predict(test_input)
        
        print(f"\n   â±ï¸  ì˜ˆìƒ ì‹œê°„: {prediction['estimated_time_minutes']} ë¶„")
        print(f"   ğŸ“Š ì‹ ë¢° êµ¬ê°„: {prediction['confidence_interval']['min_minutes']} ~ "
              f"{prediction['confidence_interval']['max_minutes']} ë¶„")
        print(f"   ğŸ¯ ì‹ ë¢°ë„: {prediction['confidence_level']}")
        print(f"   ğŸ“ˆ ìœ ì‚¬ ì¼€ì´ìŠ¤: {prediction['similar_cases_count']}ê°œ")
        print(f"   ğŸ” ë°ì´í„° ì¶œì²˜: {prediction['data_source']}")
        
        # ìµœì í™” ì œì•ˆ
        suggestions = predictor.get_optimization_suggestions(test_input, prediction)
        if suggestions:
            print(f"\n   ğŸ’¡ ìµœì í™” ì œì•ˆ:")
            for suggestion in suggestions:
                print(f"      {suggestion}")
    
    print("\n" + "=" * 60)


if __name__ == "__main__":
    main()
